{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a5c2153",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7a5c2153"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/research-assistant.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239974-lesson-4-research-assistant)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b"
      },
      "source": [
        "# Research Assistant\n",
        "\n",
        "## Review\n",
        "\n",
        "We've covered a few major LangGraph themes:\n",
        "\n",
        "* Memory\n",
        "* Human-in-the-loop\n",
        "* Controllability\n",
        "\n",
        "Now, we'll bring these ideas together to tackle one of AI's most popular applications: research automation.\n",
        "\n",
        "Research is often laborious work offloaded to analysts. AI has considerable potential to assist with this.\n",
        "\n",
        "However, research demands customization: raw LLM outputs are often poorly suited for real-world decision-making workflows.\n",
        "\n",
        "Customized, AI-based [research and report generation](https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag) workflows are a promising way to address this.\n",
        "\n",
        "## Goal\n",
        "\n",
        "Our goal is to build a lightweight, multi-agent system around chat models that customizes the research process.\n",
        "\n",
        "`Source Selection`\n",
        "* Users can choose any set of input sources for their research.\n",
        "  \n",
        "`Planning`\n",
        "* Users provide a topic, and the system generates a team of AI analysts, each focusing on one sub-topic.\n",
        "* `Human-in-the-loop` will be used to refine these sub-topics before research begins.\n",
        "  \n",
        "`LLM Utilization`\n",
        "* Each analyst will conduct in-depth interviews with an expert AI using the selected sources.\n",
        "* The interview will be a multi-turn conversation to extract detailed insights as shown in the [STORM](https://arxiv.org/abs/2402.14207) paper.\n",
        "* These interviews will be captured in a using `sub-graphs` with their internal state.\n",
        "   \n",
        "`Research Process`\n",
        "* Experts will gather information to answer analyst questions in `parallel`.\n",
        "* And all interviews will be conducted simultaneously through `map-reduce`.\n",
        "\n",
        "`Output Format`\n",
        "* The gathered insights from each interview will be synthesized into a final report.\n",
        "* We'll use customizable prompts for the report, allowing for a flexible output format.\n",
        "\n",
        "![Screenshot 2024-08-26 at 7.26.33 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb164d61c93d48e604091_research-assistant1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6",
      "metadata": {
        "scrolled": true,
        "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914",
      "metadata": {
        "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ba917800-10e4-4e2a-8e9e-30893b731e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "ba917800-10e4-4e2a-8e9e-30893b731e97",
        "outputId": "1babe1ee-7444-40ed-f381-68786b9e9257"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2315102774.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open ai API key to be placed here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2315102774.py\u001b[0m in \u001b[0;36m_set_env\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open ai API key to be placed here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"open ai API key to be placed here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9ff57-0826-4669-b88b-4d0501a509f5",
      "metadata": {
        "id": "afe9ff57-0826-4669-b88b-4d0501a509f5"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"Open ai api key is to be used here \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3419257b-2c6b-4d68-ae38-4a266cc02982",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "3419257b-2c6b-4d68-ae38-4a266cc02982"
      },
      "source": [
        "We'll use [LangSmith](https://docs.langchain.com/langsmith/home) for [tracing](https://docs.langchain.com/langsmith/observability-concepts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d"
      },
      "outputs": [],
      "source": [
        "_set_env(\"Lang key is to be used here \")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea",
      "metadata": {
        "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea"
      },
      "source": [
        "## Generate Analysts: Human-In-The-Loop\n",
        "\n",
        "Create analysts and review them using human-in-the-loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e",
      "metadata": {
        "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Analyst(BaseModel):\n",
        "    name: str\n",
        "    role: str\n",
        "    affiliation: str\n",
        "    specialization: str\n",
        "    description: str\n",
        "    confidence_score: float = 0.8\n",
        "\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return (\n",
        "            f\"Name: {self.name}\\n\"\n",
        "            f\"Role: {self.role}\\n\"\n",
        "            f\"Affiliation: {self.affiliation}\\n\"\n",
        "            f\"Specialization: {self.specialization}\\n\"\n",
        "            f\"Confidence: {self.confidence_score}\\n\"\n",
        "            f\"Description: {self.description}\\n\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NiXRrkth4Ah"
      },
      "id": "0NiXRrkth4Ah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
        "outputId": "8cb85fb6-aca3-4293-fdaf-bca8400b2be9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "# ----------------------------- Dummy LLM Setup -----------------------------\n",
        "class DummyLLM:\n",
        "    \"\"\"Simulated LLM to work without API key\"\"\"\n",
        "    def with_structured_output(self, model):\n",
        "        return self\n",
        "\n",
        "    def invoke(self, messages):\n",
        "        # Create mock analysts to simulate real LLM structured output\n",
        "        mock_analysts = [\n",
        "            {\"name\": \"Dr. Mira Chen\", \"role\": \"AI Policy Analyst\", \"affiliation\": \"Tech Policy Lab\", \"specialization\": \"Ethical AI frameworks\"},\n",
        "            {\"name\": \"Prof. Raj Patel\", \"role\": \"Data Scientist\", \"affiliation\": \"Open Data Institute\", \"specialization\": \"Data transparency and analysis\"},\n",
        "            {\"name\": \"Elena Rossi\", \"role\": \"Machine Learning Engineer\", \"affiliation\": \"NeuralWorks\", \"specialization\": \"Model optimization and deployment\"}\n",
        "        ]\n",
        "        class MockOutput:\n",
        "            analysts = [Analyst(**a) for a in mock_analysts]\n",
        "        return MockOutput()\n",
        "\n",
        "# Replace ChatOpenAI with DummyLLM\n",
        "llm = DummyLLM()\n",
        "\n",
        "# ----------------------------- Data Models -----------------------------\n",
        "class Analyst(BaseModel):\n",
        "    name: str = Field(description=\"Name of the analyst.\")\n",
        "    role: str = Field(description=\"Role of the analyst in the context of the topic.\")\n",
        "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
        "    specialization: str = Field(description=\"Area of specialization for the analyst.\")\n",
        "\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return (\n",
        "            f\"Name: {self.name}\\n\"\n",
        "            f\"Role: {self.role}\\n\"\n",
        "            f\"Affiliation: {self.affiliation}\\n\"\n",
        "            f\"Specialization: {self.specialization}\\n\"\n",
        "        )\n",
        "\n",
        "class Perspectives(BaseModel):\n",
        "    analysts: List[Analyst] = Field(\n",
        "        description=\"List of analysts with their details and expertise areas.\"\n",
        "    )\n",
        "\n",
        "class GenerateAnalystsState(TypedDict):\n",
        "    topic: str\n",
        "    max_analysts: int\n",
        "    human_analyst_feedback: str\n",
        "    analysts: List[Analyst]\n",
        "\n",
        "# ----------------------------- Analyst Creation Logic -----------------------------\n",
        "analyst_instructions = \"\"\"\n",
        "You are tasked with creating AI analyst personas. Follow these structured steps:\n",
        "\n",
        "1. Review the research topic carefully: {topic}\n",
        "2. Consider human feedback (if any): {human_analyst_feedback}\n",
        "3. Identify unique subtopics relevant to the research area.\n",
        "4. Create {max_analysts} analysts, each specializing in a distinct aspect.\n",
        "5. Define clear name, affiliation, role, and specialization for each analyst.\n",
        "\"\"\"\n",
        "\n",
        "def create_analysts(state: GenerateAnalystsState):\n",
        "    \"\"\"Create analysts using simulated LLM structured output\"\"\"\n",
        "    topic = state[\"topic\"]\n",
        "    max_analysts = state[\"max_analysts\"]\n",
        "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
        "\n",
        "    structured_llm = llm.with_structured_output(Perspectives)\n",
        "    system_message = analyst_instructions.format(\n",
        "        topic=topic,\n",
        "        human_analyst_feedback=human_analyst_feedback,\n",
        "        max_analysts=max_analysts\n",
        "    )\n",
        "\n",
        "    analysts = structured_llm.invoke(\n",
        "        [SystemMessage(content=system_message)] +\n",
        "        [HumanMessage(content=\"Generate the analyst profiles based on these instructions.\")]\n",
        "    )\n",
        "\n",
        "    return {\"analysts\": analysts.analysts}\n",
        "\n",
        "def human_feedback(state: GenerateAnalystsState):\n",
        "    \"\"\"Pause point for human feedback\"\"\"\n",
        "    pass\n",
        "\n",
        "def should_continue(state: GenerateAnalystsState):\n",
        "    \"\"\"Conditional logic for next node\"\"\"\n",
        "    if state.get(\"human_analyst_feedback\"):\n",
        "        return \"create_analysts\"\n",
        "    return END\n",
        "\n",
        "# ----------------------------- Graph Construction -----------------------------\n",
        "builder = StateGraph(GenerateAnalystsState)\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_conditional_edges(\"human_feedback\", should_continue, [\"create_analysts\", END])\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
        "\n",
        "# ----------------------------- Visualize Graph -----------------------------\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
        "outputId": "e5757b9a-2d0e-4655-eada-6e8a6bfa47e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Analysts:\n",
            "============================================================\n",
            "Name: Dr. Mira Chen\n",
            "Affiliation: Tech Policy Lab\n",
            "Role: AI Policy Analyst\n",
            "Specialization: Ethical AI frameworks\n",
            "------------------------------------------------------------\n",
            "Name: Prof. Raj Patel\n",
            "Affiliation: Open Data Institute\n",
            "Role: Data Scientist\n",
            "Specialization: Data transparency and analysis\n",
            "------------------------------------------------------------\n",
            "Name: Elena Rossi\n",
            "Affiliation: NeuralWorks\n",
            "Role: Machine Learning Engineer\n",
            "Specialization: Model optimization and deployment\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langsmith/client.py:292: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "max_analysts = 3\n",
        "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream(\n",
        "    {\"topic\": topic, \"max_analysts\": max_analysts},\n",
        "    thread,\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    analysts = event.get(\"analysts\", \"\")\n",
        "    if analysts:\n",
        "        print(\"\\nGenerated Analysts:\\n\" + \"=\" * 60)\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Specialization: {analyst.specialization}\")\n",
        "            print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
        "outputId": "412cfe1d-c079-4fd4-aaba-0f05eef35bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next node to execute: ('human_feedback',)\n"
          ]
        }
      ],
      "source": [
        "# Check current graph state and next execution node\n",
        "state = graph.get_state(thread)\n",
        "\n",
        "# Safely print the next node to be executed\n",
        "if hasattr(state, \"next\"):\n",
        "    print(\"Next node to execute:\", state.next)\n",
        "else:\n",
        "    print(\"State tracking not available or no next node scheduled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
        "outputId": "3f8e8e17-6da3-473a-9320-84e61f2bb69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Human feedback added successfully.\n"
          ]
        }
      ],
      "source": [
        "# Simulate human-in-the-loop feedback by updating the graph state manually\n",
        "feedback_text = \"Add in someone from a startup to add an entrepreneur perspective\"\n",
        "\n",
        "try:\n",
        "    graph.update_state(\n",
        "        thread,\n",
        "        {\"human_analyst_feedback\": feedback_text},\n",
        "        as_node=\"human_feedback\"\n",
        "    )\n",
        "    print(\"✅ Human feedback added successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Could not update state (offline simulation). Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8816eb9-9906-441b-b552-be71107db14f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8816eb9-9906-441b-b552-be71107db14f",
        "outputId": "dacbecbb-eab2-43da-d347-c3021e121b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Analysts After Feedback:\n",
            "============================================================\n",
            "Name: Dr. Mira Chen\n",
            "Affiliation: Tech Policy Lab\n",
            "Role: AI Policy Analyst\n",
            "Specialization: Ethical AI frameworks\n",
            "------------------------------------------------------------\n",
            "Name: Prof. Raj Patel\n",
            "Affiliation: Open Data Institute\n",
            "Role: Data Scientist\n",
            "Specialization: Data transparency and analysis\n",
            "------------------------------------------------------------\n",
            "Name: Elena Rossi\n",
            "Affiliation: NeuralWorks\n",
            "Role: Machine Learning Engineer\n",
            "Specialization: Model optimization and deployment\n",
            "------------------------------------------------------------\n",
            "\n",
            "Updated Analysts After Feedback:\n",
            "============================================================\n",
            "Name: Dr. Mira Chen\n",
            "Affiliation: Tech Policy Lab\n",
            "Role: AI Policy Analyst\n",
            "Specialization: Ethical AI frameworks\n",
            "------------------------------------------------------------\n",
            "Name: Prof. Raj Patel\n",
            "Affiliation: Open Data Institute\n",
            "Role: Data Scientist\n",
            "Specialization: Data transparency and analysis\n",
            "------------------------------------------------------------\n",
            "Name: Elena Rossi\n",
            "Affiliation: NeuralWorks\n",
            "Role: Machine Learning Engineer\n",
            "Specialization: Model optimization and deployment\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Continue the graph execution after adding human feedback\n",
        "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
        "    analysts = event.get(\"analysts\", \"\")\n",
        "    if analysts:\n",
        "        print(\"\\nUpdated Analysts After Feedback:\\n\" + \"=\" * 60)\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Specialization: {analyst.specialization}\")\n",
        "            print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43ac322-5926-4932-8653-68206fec0d2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a43ac322-5926-4932-8653-68206fec0d2c",
        "outputId": "44051567-31fc-4c9e-8a8b-d21268f67472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No further feedback supplied. Proceeding to finalize analysts.\n"
          ]
        }
      ],
      "source": [
        "# Final step: simulate that we have no further human feedback\n",
        "further_feedback = None\n",
        "\n",
        "try:\n",
        "    graph.update_state(\n",
        "        thread,\n",
        "        {\"human_analyst_feedback\": further_feedback},\n",
        "        as_node=\"human_feedback\"\n",
        "    )\n",
        "    print(\"✅ No further feedback supplied. Proceeding to finalize analysts.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Could not update state (offline simulation). Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab034e65-aeee-4723-8d6d-74541b548425",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab034e65-aeee-4723-8d6d-74541b548425",
        "outputId": "0f584611-7630-4654-cdd0-b86426fbdfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Continuing graph execution until the end...\n",
            "\n",
            "\n",
            "✅ Graph execution completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Continue executing the graph until completion\n",
        "print(\"🚀 Continuing graph execution until the end...\\n\")\n",
        "\n",
        "try:\n",
        "    for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
        "        print(\"-- Node Execution --\")\n",
        "        node_name = next(iter(event.keys()), None)\n",
        "        if node_name:\n",
        "            print(f\"Currently executing node: {node_name}\")\n",
        "        else:\n",
        "            print(\"No active node found in this update.\")\n",
        "        print(\"-\" * 50)\n",
        "    print(\"\\n✅ Graph execution completed successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Graph execution could not be completed (offline simulation). Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f204e8a-285c-4e46-8223-a695caec7764",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f204e8a-285c-4e46-8223-a695caec7764",
        "outputId": "c2cb36f3-9f8f-4da9-9620-5f1032caf1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Final List of Analysts:\n",
            "============================================================\n",
            "Name: Dr. Mira Chen\n",
            "Affiliation: Tech Policy Lab\n",
            "Role: AI Policy Analyst\n",
            "Specialization: Ethical AI frameworks\n",
            "------------------------------------------------------------\n",
            "Name: Prof. Raj Patel\n",
            "Affiliation: Open Data Institute\n",
            "Role: Data Scientist\n",
            "Specialization: Data transparency and analysis\n",
            "------------------------------------------------------------\n",
            "Name: Elena Rossi\n",
            "Affiliation: NeuralWorks\n",
            "Role: Machine Learning Engineer\n",
            "Specialization: Model optimization and deployment\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the final state of the graph\n",
        "final_state = graph.get_state(thread)\n",
        "\n",
        "# Safely extract the list of analysts from the final state\n",
        "analysts = final_state.values.get(\"analysts\") if hasattr(final_state, \"values\") else None\n",
        "\n",
        "if analysts:\n",
        "    print(\"\\n📊 Final List of Analysts:\\n\" + \"=\" * 60)\n",
        "    for analyst in analysts:\n",
        "        print(f\"Name: {analyst.name}\")\n",
        "        print(f\"Affiliation: {analyst.affiliation}\")\n",
        "        print(f\"Role: {analyst.role}\")\n",
        "        print(f\"Specialization: {analyst.specialization}\")\n",
        "        print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"⚠️ No analysts found in the final graph state.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
        "outputId": "8afc06e4-beb5-4943-ebc1-698e783fb8b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "final_state.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf",
      "metadata": {
        "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class Analyst(BaseModel):\n",
        "    name: str = Field(description=\"Name of the analyst.\")\n",
        "    role: str = Field(description=\"Role of the analyst in the topic context.\")\n",
        "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
        "    description: str = Field(description=\"Brief description of the analyst's focus, concerns, and motives.\")\n",
        "\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return (\n",
        "            f\"Name: {self.name}\\n\"\n",
        "            f\"Role: {self.role}\\n\"\n",
        "            f\"Affiliation: {self.affiliation}\\n\"\n",
        "            f\"Description: {self.description}\\n\"\n",
        "        )\n",
        "\n",
        "class Perspectives(BaseModel):\n",
        "    analysts: List[Analyst] = Field(\n",
        "        description=\"List of all analysts with their details.\"\n",
        "    )\n",
        "\n",
        "class GenerateAnalystsState(TypedDict):\n",
        "    topic: str\n",
        "    max_analysts: int\n",
        "    human_analyst_feedback: str\n",
        "    analysts: List[Analyst]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7",
      "metadata": {
        "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7"
      },
      "source": [
        "## Conduct Interview\n",
        "\n",
        "### Generate Question\n",
        "\n",
        "The analyst will ask questions to the expert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c",
      "metadata": {
        "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, List\n",
        "from langgraph.graph import MessagesState\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class InterviewState(MessagesState):\n",
        "    \"\"\"State representation for conducting interviews with analysts.\"\"\"\n",
        "\n",
        "    max_num_turns: int = Field(\n",
        "        description=\"Maximum number of conversational turns allowed in the interview.\"\n",
        "    )\n",
        "    context: Annotated[List[str], operator.add] = Field(\n",
        "        description=\"List of relevant documents or knowledge snippets added as interview context.\"\n",
        "    )\n",
        "    analyst: Analyst = Field(\n",
        "        description=\"The AI analyst persona currently conducting or responding in the interview.\"\n",
        "    )\n",
        "    interview: str = Field(\n",
        "        description=\"Complete interview transcript between the analyst and the interviewer.\"\n",
        "    )\n",
        "    summary: str = Field(\n",
        "        default=\"\", description=\"Summarized version of the key takeaways from the interview.\"\n",
        "    )\n",
        "    sections: List[str] = Field(\n",
        "        default_factory=list, description=\"Structured output sections for use with the Send() API.\"\n",
        "    )\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    \"\"\"Structured query for fetching relevant research documents.\"\"\"\n",
        "\n",
        "    query_text: str = Field(\n",
        "        None, description=\"Refined search query string to retrieve topic-relevant information.\"\n",
        "    )\n",
        "    filters: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Optional filters such as date range, author, or source to narrow the search scope.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0",
      "metadata": {
        "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0"
      },
      "outputs": [],
      "source": [
        "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
        "\n",
        "Your goal is boil down to interesting and specific insights related to your topic.\n",
        "\n",
        "1. Interesting: Insights that people will find surprising or non-obvious.\n",
        "\n",
        "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
        "\n",
        "Here is your topic of focus and set of goals: {goals}\n",
        "\n",
        "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
        "\n",
        "Continue to ask questions to drill down and refine your understanding of the topic.\n",
        "\n",
        "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
        "\n",
        "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
        "\n",
        "def generate_question(state: InterviewState):\n",
        "    \"\"\" Node to generate a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Generate question\n",
        "    system_message = question_instructions.format(goals=analyst.persona)\n",
        "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
        "\n",
        "    # Write messages to state\n",
        "    return {\"messages\": [question]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2ff33a-6232-4a79-8a82-882a645394f5",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "be2ff33a-6232-4a79-8a82-882a645394f5"
      },
      "source": [
        "### Generate Answer: Parallelization\n",
        "\n",
        "The expert will gather information from multiple sources in parallel to answer questions.\n",
        "\n",
        "For example, we can use:\n",
        "\n",
        "* Specific web sites e.g., via [`WebBaseLoader`](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base)\n",
        "* Indexed documents e.g., via [RAG](https://docs.langchain.com/oss/python/langchain/retrieval)\n",
        "* Web search\n",
        "* Wikipedia search\n",
        "\n",
        "You can try different web search tools, like [Tavily](https://tavily.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606ea95b-e811-4299-8b66-835d4016c338",
      "metadata": {
        "editable": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606ea95b-e811-4299-8b66-835d4016c338",
        "outputId": "89b1fcb1-acbe-4cf9-8d7d-0d6fe37d9cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ],
      "source": [
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789",
      "metadata": {
        "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789"
      },
      "outputs": [],
      "source": [
        "# Web search simulation tool (Offline + Unique)\n",
        "# This simulates how a web search retriever would behave in a research assistant setup.\n",
        "\n",
        "class MockWebSearch:\n",
        "    \"\"\"A simulated web search tool for retrieving relevant documents without API calls.\"\"\"\n",
        "\n",
        "    def __init__(self, max_results: int = 3):\n",
        "        self.max_results = max_results\n",
        "\n",
        "    def run(self, query: str):\n",
        "        mock_results = [\n",
        "            f\"Result 1: Key insights about '{query}' from AI research blogs.\",\n",
        "            f\"Result 2: Discussion on how LangGraph improves multi-agent workflows.\",\n",
        "            f\"Result 3: Technical summary linking parallelism and agent coordination in LangChain.\"\n",
        "        ]\n",
        "        return mock_results[:self.max_results]\n",
        "\n",
        "# Initialize the simulated web search tool\n",
        "web_search = MockWebSearch(max_results=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c",
      "metadata": {
        "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c"
      },
      "outputs": [],
      "source": [
        "# Wikipedia search simulation tool (Offline + Unique)\n",
        "# This mock loader simulates how WikipediaLoader would retrieve topic-specific information.\n",
        "\n",
        "class MockWikipediaLoader:\n",
        "    \"\"\"Simulates Wikipedia document retrieval for the research assistant.\"\"\"\n",
        "\n",
        "    def __init__(self, query: str):\n",
        "        self.query = query\n",
        "\n",
        "    def load(self):\n",
        "        mock_docs = [\n",
        "            {\"title\": \"LangGraph Overview\", \"content\": \"LangGraph is a framework designed for building multi-agent AI workflows with persistent state.\"},\n",
        "            {\"title\": \"Parallel Processing\", \"content\": \"Parallelization allows multiple tasks or agents to execute simultaneously, improving efficiency.\"},\n",
        "            {\"title\": \"AI Research Assistants\", \"content\": \"Research assistants use retrieval and reasoning to produce source-grounded, structured outputs.\"}\n",
        "        ]\n",
        "        return mock_docs\n",
        "\n",
        "# Example initialization (like WikipediaLoader but simulated)\n",
        "wiki_loader = MockWikipediaLoader(\"LangGraph\")\n",
        "wiki_docs = wiki_loader.load()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cb1603",
      "metadata": {
        "id": "06cb1603"
      },
      "source": [
        "Now, we create nodes to search the web and wikipedia.\n",
        "\n",
        "We'll also create a node to answer analyst questions.\n",
        "\n",
        "Finally, we'll create nodes to save the full interview and to write a summary (\"section\") of the interview."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
        "outputId": "13950fcc-f843-47da-b995-332f0abf8343"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAJ2CAIAAADNP57VAAAQAElEQVR4nOydB0DUSBfHJ7vA0pEiKiAgdsWG3c/eez9717N71rP33vXsp57tznp2PXvvXZq9F6oC0suyyfeygXWBZWF1N+xu3u+4NZlMJpNk5p83byYTE4ZhCIIgiPYwIQiCIFoFZQVBEC2DsoIgiJZBWUEQRMugrCAIomVQVhAE0TIoK4g+ISP3L0aFvE9MSqClyXRqEkMoeTj8K2YYGUUohqIohoZVwtAMYSgiIgRWKUIzsEJRIkLLCPxyezEU+x8bB1ZodivsK99NHhOSlY+vYONDcgy3G5s4Tct3JFzU7/uyyI+oQGxGxKYiM3MTx4Km5f5n61jIjAgeCsetIPrA8T+Dwz4kp6TITE3FphJKYiEWiZmURHn1FbGaQZmKGCkNyxRh5LIiL7oQIKJAAuThNMNWfq5IwyphFyi5JEEgRROZQhrYUDYFWJSxP2wEVnfSMsNuotn909bFFERj49DyyKBosu85N5GIaJqkJNFJ8TJZKi02Edk7mzXoUqCgh3D1BWUFyWP2r/z85XOSpY24WHmbup2ciIHz6NK3p3djvoWnWNiIu47xsHYQEeGBsoLkGY8uRd87G2FlZ9J5hKuFnZgYF0fWBwe9TnAtatlhpAsRGCgrSN5wZF1I+KfEpn0KFSlrQYyXbTPegTdo4FxPIiRQVpA84NbJyBf34/rPcScC4PjGkKivKX1neBDBgLKC8M2/qz7FRMkE9QA/8Wdo6IeEXxd6EWEgRH8Skoec+zs8JlJYmgK0GVKwgIfFzrkfiDBAWUH4IzZS9tI3duA8TyI82g4pJJUyZ3eFEQGAsoLwx/5Vn0pUsiFCpft4j9f+cUQAoKwgPPHwQrQ0Sda0lzMRKlb5qHxOpnuWfSLGDsoKwhOPr0QWKStcU4Wj3UDXyJBkYuygrCB8EBtFJyfKmvfj1VQ5cODArFmziOZMnjz52LFjRAdY5xdLLMRn/zZyDwvKCsIHVw6GSiz4fq/16dOn5If44R1zQyFPi08v44lRg7KC8EFkiNTZXUJ0w/v378G+aNKkSePGjceNG+fr6wuBgwcPPnny5H///VelSpXnz59DyP79+0eOHFm/fv1mzZpNmTLl8+fP3O779u2DkCtXrlSrVm358uUQPzg4eN68eRCT6IDydexSkox8sBjKCsIHCfGphYtZEh2QkpICCiIWi9euXbtx40YTE5OxY8cmJSVt3rzZ29u7VatWDx48KFWqFGjNsmXLKlSoAMIxZ86cyMjI6dOncymYmZnFx8cfPHhw7ty5Xbp0uXnzJgTOmDEDhIboAPdSFgwDOptKjBecbwXhA4Ymhbx08u7Phw8fQCO6d+8O2gGrixcvfvToUWpq5kpbrlw5cLW4u7uD7sCqVCoF9YmOjrazs6MoCmSob9++VatWhU3JyTp3qZqYUB9fJDoUMloHNsoKwgs0Keiik/lHQCns7e1nz57dsmXLypUrgz0CrZis0cCcgVbPihUrAgMDwTbhAkGPQFa45bJlyxK+oER0dCSIl9HKCjaCED4AXwKtm5kPJBLJli1bateuvWfPnoEDB7Zv3/7UqVNZo129ehXcLmXKlIHI9+/fX7duXaYI0BQivMGwk00R4wVlBeEDiiJRYTKiGzw9PceMGQMO2pUrVxYrVmzmzJmcj1aZI0eOVKxYccSIESVKlIBWT2xsLMk7aJpY2xnz3HEoKwg/MEFvddKrCt1Ax48fhwVzc/O6desuWbIEvCfPnj3LFA3cKM7O30fNXLp0ieQddCpT0MuYZ5lBWUH4wMRM9OGpTmQF9AJ6cFavXv3p0ydw327fvh38teBhgU2FCxcGTwo0ecCHAkbKnTt3oFcItu7evZvbNyQkJGuC0KoCAVJEJtrm60cptH9cvNBaQZCfI7+L+ddgnfSwgIJMnTr19OnTHTp06NSp0+PHjzdt2uTlxc5s0rFjR2jvQMPn1atXw4cPr1WrFrhXatasGRoaCn3M4Gf57bffzpw5kzXNAQMGgBiNHz8+MTGRaJvHVyPNzI283uE0TggfBL1OPLIhaOTKYkTwbJ321tFV0mG4KzFe0FpB+MC1mIVITK4c/EoET2KCrN0gY9YUguNWEN4oVdnu2b3o+p2z/WTHpEmT7t69q3IT+Di4YWxZmT17to5G2QPZpSyTycDMzy5LFy5cyG7TgZWfrGxNRMb+BSFsBCH8sX7C64p17f/X1lHl1oiIiOxGuEI4eFJVbnJwcIA+IKIbgoODs9ukJksuLtl+wWPd2Nf9pntZOxp5KwGtFYQ/GnYudPlQaHay4ujoSPQMNQLxA+yY+8HZzdzoNYWgbwXhk9I1rJwKSf5e+JEIj2uHI5IT6C7j3YgAQFlBeKXLODeZlP53dRAREm/8EgJvfxuyuAgRBuhbQfKAg2uCUhLpHpMKEwHw4Fz0g0sRQxcL5SNBBGUFySt2zX9PS6l+c4z8W3/7V3yODE8etqQoERIoK0iecXJz2IcXcZ5lrFoNLEiMjjunox5ejLCwEg+YI5S2jwKUFSQviYukD675lBCb6uhiXqddfpdiBj+iQ5pETu0MCXmbQNOkciOH6s3tifBAWUHynreBSTeOhcdGSUUUMbcSW9uZWNmZiMUkJYVWxIFVGTezAsVO3yISEXabfDu7TBNKxM5BR1HfizRFEVikRGk70emJsSE0211BEYqmGS4FhnC7wwrFyJj0fdl/uR3FYkomY0Ty1Ojv+SImEhFFU3HRqZD/hLhUSMTMXFS2Wr7/tXcgQgVlBdEj/K7HvA+Mj42WgkOXljHSlO+FUySmIESxCtWdVQombZmVAKVfRRw2BPRCHhmWGTliMdcBysZm6LSYhCh2Z9iA9NS4cDYDJgydSimHcJiawiYRyI2lrYlrMYv/tdG70Tf8g7KCCIgTJ048evToxz4ehOQeHGWLCAg17xYhWgQvMSIgUFb4AS8xIiBQVvgBLzEiIKRSqSm4WBEdg7KCCAi0VvgBLzEiIFBW+AHfYEYEhEwmQ1nhAZQVRECAbwVlhQfwEiMCAhtB/ICXGBEQKCv8gJcYERAoK/yAlxgRECgr/ICXGBEQOByOH1BWEAGB1go/4CVGBATKCj/gJUYEBMoKP+AlRgQE+lb4AWUFERBorfADXmJEQKCs8ANeYkRAoKzwA15iRECgrPADXmJEQICsoMuWB1BWEAGB1go/4CVGBISjo6NYLCaIjkFZQQREVFRUSkoKQXQMygoiIKAFBO0ggugYlBVEQKCs8APKCiIgUFb4AWUFERAoK/yAsoIICJQVfkBZQQQEygo/oKwgAgJlhR9QVhABgbLCDygriIBAWeEHlBVEQKCs8APKCiIgUFb4AWUFERAoK/yAsoIICJQVfkBZQQQEygo/oKwgAgJlhR9QVhABgbLCDxTDMARBjJpWrVqFhIRAUacoiguBZXd392PHjhFEB4gIghg7bdq0EYlEYrFYlA6YLe3atSOIbkBZQYyfXr16gW2iHFK4cOEOHToQRDegrCDGj7W1NYiI8pz7DRo0sLe3J4huQFlBBEHXrl1dXFy4ZVjo3LkzQXQGygoiCMzMzEBZJBIJLNesWbNQoUIE0RnYE4T8FPfPfIsMT05JlilCxKYimYwmdPqqiJLRDCUijDwEumIYAv8z0CUDJU8E4UTE0Ow2iAOB7CIbiZGHUPJOG3lUOWx8hmQqs5SYYmRwCIqh0zak7UhDSt9LOKR//959aWpqhYoVLM0t0wLlh4Jk6YyR00Lk2VZOmX0Qc6cmPwHu0PL4FE1/zxa7I6M4i7RzV0YkpmgZwx1FJaamIqt8ZrWaOYgtiMGBsoL8IJf2Rbx8GC0ypURiIk1SqlFihtCUolilVSoqXRrk9Z39J01XCFtNaRG3ia3kbDWTR0jTIPmKInkR4YIYiv0v/YiEkckjpYdkTSrt0IRVMDFX5xWBjKLmf4+snG252qSHU+miRmXIRibtkMtKen6o77L4PQKVdhlINvVPDBdWRJKTaHtnSY+JbsSgQFlBfoRHF6MfXIhq0svFyc2MILrkyLrPFtbUL6NdieGAsoJozL3T0b43orpP9CQIL5z88zOYP90mGIzNgi5bRGMCbkYVq2BHEL5oPcQtMiyZGA4oK4jGJKfIvGvhoA9eMTUT3T4ZRQwEfNUQ0QxZCqFTaQsbgvCJLJVJjDOYlyRRVhCN+d6NgvCFTMaAshADAWUFQRAtg7KCIIiWQVlBEETLoKwgiAHAvthAoW8FMVZUveGC6BqaKL2aoPegrCAaIn8BD0HUgLKCIIiWQVlBNATHrCA5gbKCaAi+morkBMoKoiEitFfyALEJEZtiTxBirNBor+QBslQikxqMnqNPH9FHDh3e16hJNaL3GEo+eQZlBUE048jRA4uWzOKWy5T27t1rEEEygo0gBNGMFy+eKpZLl/aGP4JkBGUF0ZAfMnAPH9l/5871Z88CzSSSCuV9Bg4c4erCTqHIMMyhw3vPnj356fMHD/ciVarUGNB/mFgsVt5XJpNNmjwqNCxk/boddrbqZqXb9Ocf587/FxUV2bJFuzq1G0yZNubggTOOjk6wAFsXLVjNRYPDLV46+78T1ywtLVNTU//atuHO3Rvh4aHe3hU7tOtSo0ZtLtrHj++379jk6/cQMlm2bPluXfqUK1dxzLjBfn6PYOu5c//9uemfgADfDRtXXjx/j9tl199bz547+fVruLNzwYoVKo8dM0UkYq9X+46N+/cbGh39beeuzRYWFlWr1Bw5YgJkjOQa9uPRhuMqx0YQoiGaj9yHurd23bKyZSvMnbt88qQ5UO0XLJzObTp8eN8/u7d17tRj356Tbdp0+u/U0X37d2XafenyuS9fPlu6ZJ16TTn535GDh/aMGT352NFLZcqUW7t+OQQqf8lQJWvWLoW9OrTvumf3iXp1G82aM/HqtYsQnpKSAgoCArdk8doVyzaaiE2mTR+blJS0euVmME+aNm11+eKDEsVLKScFGnT02IFhQ8Yc/PfswAHDr1w9/+/B3dwmU1PT/ft3gcQcPXJx5/ZDAYG+O3b+STSB/VKBCHuCEGNF82cmVPLtfx1wc3PnKnmqVDp1+tjomGiQCT//RyVLlmnWrDWEt27VoVKlqokJCcr7wvP/8uVzK5dvcimUw9Tzp88cBwulbp2GsNyqZfunTwOCgz+r3yU5ORmMix7d+7Vt0wlWwcYJDPTb9fcW0JdPnz6A/HXq2J3TjlkzF0NWwbTJLqnYuNi9+3YOGzq2du36sFq/XuO3b1/9s/uvjh26gaZAiKtr4V49B7BRrW3AWgGhJJpAMwyRYU8QYqxo/siEZz7U8ClTR7duW69BoyqgKRD4LSoSfr29Kzx8eHfpsrlnzp4AoYGWUbFiJQhr87NcuHgGTICpU+ZBtByP8vr1C1AoxSpoGUn7dlm2QN0GqwQquSIEWi5v376GnIAI5stnD20lMKZAa8DQqFSxirW1dXZJgQxJpVJlP0uJEqXj4uKCgj4pVhWbfcH5kwAAEABJREFUbGxs4+PjiPGC1gqic27evDp95viePfoPGTy6aNHiDx7enThpJLcJmj+WllY3b11dsnQO2DL16zcZ8utvTk75QQ7ApbJY3uFiLjHP8RDx8fEgEBYWlooQc/OcvwYYFxcLv6NGD8wUHhUZ4enp9ceqLdAogyYSOF9cXNz69RncpEnL7JKKjPyaKatcZhIT04wvihLQKEKUFURD2FG2mlksJ08dAWfnoIEjuFWuMqclJhJB2wf+3r9/++jRvR27NsNjfOH8VdzW8eOmQdMDTAZoQ9nbO6g5BDhfwSZKTk5ShCjqc1ZkdNqnXR2d8nNHgRaKcgRwuMKvu7vnsKFjwNUKGYMW1sLFMz08vTL5UxRYWbGGTGJSoiIkISEefh0cNPDLGg3YCEI0hJZ/RFkTYmKi8zs5K1avX7+kWIZOmXfv3sACWAcdO3YDXwa0ZbhNoDgtmrcdPWqSpYWlwsWbHWALFCzootz16x/wWLFsZmrGVXIOaLBwC26u7tzH3qGBw/15enhBhxSIFHQDgZQQ1uoxr1Wr7uxZS8CYUuMQKVq0BOjakyd+ihDo9rKxtsmf35loA7ZDSWwwLluUFUTnFCta4v6DO499H4DLU9E5Ah3G8Hvx0pmZs3+/desauDPu3Llx/cYl77IZ3CjQHTt79lLo5T3w7z/qjwJe0kuXz0E/TkJCAvRn37t3S7EJXB7Pnz8BpwksQxPsxs0rXDjIR7++Q8BHC31V0IaCfSdMHL76j8VELoXg8dm4afXnoE8gQ7v3bIfMc3kD0wYk49Hj+1Fy9xCHrY1tk8YtwRED5xITGwPdz0eO7u/cuSfXwfzzsF+ANxyXLTaCEJ0zYMBwMBamzxiXmJgIPSPQxxwSEjR5ym/Tps4fP276uvXLp80YR9j2giO0hn7p3CvT7tDu6NP71y1b11WpXMPLq1h2R+nVc2BExNc/1iyB2g7RoNtl/YaV3Kb27bqA9TF4aE/w1zRs0LRXjwHQsOK8ud269gFDY8++HdDSgYZM2TLlx49nLSNwEo8bOxW6gTk5q1K5+soVm8CkguU2rTqC2fL7xBHQ96ycgRHDx4OIzFswFQQIfDE9uvfv3q0vEST4DWZEM2QpZMOk1/1mFyP6zeUr5+fOm3Lk0Hno0CGGz655b0pUtGnSSztNKl2D1gqiGaxNj48i/jGoUbYoK4hmsINs86ivdMq0MYEBvio3tWzZHnptiPECLhpKjL4VxFjJu7I9Ydz0FGmKyk2WSiNWOBrUbwJ/xFiAPnEGP5aKGC15V7Y1ejcPyUNQVhANwTEJSE6grCAagt8eywtEFKHwDWYEQbQIzRCGRpctgiBCBWUFQRAtg7KCaIgI3St5APhWDOhVQ5QVRDM+f/yMnUH8A74VfNUQMSqioqLupWMmtqhfZCFBkOxBWUFUk5KSAiJy//79u3fvRkREVJMzaNAgZ8dCGya9JgiSPSgrSAYeP34MUgKC8vTpU05K5s+fX6yY0vvKMkJhI4h3zMzF8EcMBJQVhLx8+ZKTEsDb27tq1aqjRo2qUCGbWanFxMREHPI6pVAxM4LwhSyVLuSZ85y+egLKikAJCgpSSImzszNISdeuXZcvX859fUI9Ng4mvte+FCrmShBeeH43lqKoElWsiIGA0zgJiOjoaE5HQFDgvoOUcM2cfPnyEQ35c+LbKi0KlfDJeXZ75OfZvfBdzRZOFerbEAMBZcXISU1NVUhJWFiYQkpcXX/W1tg87Z2ltal7KSu7/BJapvq7XJTSC8/wvE0rbOzM/exK1vgMBSUyw37ckjxYVUEVUfKu1+/HYKeY4n4zZ4VSLutpB1AdEw6mdDh51PSMkezOLu3oJEs2lQ6RflBVJ5M5LUKZUNJE8v5JbERQUrffPfLlNxjHCkFZMVb8/Pw4KfH39+d0BASlZMmSRKscWhsSGZokkzKpUtUj5Lg6nhlKrh8qZSJdRXI9/ULGqBrsqDZJoiyHnFawwpIpYuazU3n0rIGgM3QuZsKiGJqipanR76IPf016D6oIT4j4+PhTp04RvQdlxXh48+YNdAZzHpNSpUpxUuLj40OQdE6ePPngwYPZs2cT/WbWrFlnz56FPn5uVSQS0TTN2VuPHj0ieg+6bA2b0NBQxUA1BwcHkJKOHTsuXryY+/wNkgl44Of4sXd9YM6cOYmJiZcvX1Y89UFZDEVTCMqKIRIbG6uQEqlUWr169dq1a48bNw5khSBqMRRZAZYuXdqzZ88XL14oQkBZQGssLAzATY6yYhiADawY8wp9w5y7pFevXoULFyZIrgEVzk0Pup6wcuXKIUOGfP78mVsdOHDghAkT1q9fHxMTY2trS/QYlBW9JiAggJOSx48fc1Iyffp08JsQ5IcwIGsFKFCgANzumTNnhoeHg2Nl6NChXDi4hw4ePDht2rSf787TESgresfbt28VA9WKFSsGUjJ48ODKlSsT5KcxLFkBqlSp0qdPn02bNim3fRo2bGhtbQ0eepCVa9eu1a1bl+gZ2BOkF4SFhSmkBOxb6MEBjwn8GkRD2oDYsmULNCehZUGMhX379q1du/b8+fNQVKg8+n5TVlBW8oz4+HjFQDVwxSkGqjk54WcrdMXGjRvNzMzASUGMiOTkZNBK6I0GLy8Yth4eHiSvwUYQ3yik5MOHD5yUdOvWTR+KghCARpCVlcG8WZNLuMEEYK1Aa2jPnj1TpkwBp37eul1QVvjgyZMnnJQAnJRMnDixbNmyBOEXg/OtaEQzOUT+Humvv/66atUqrY+rziUoK7oCjBHFmFdPT0+Qkn79+m3YsIEgeYdxy4oCKGw7duwICQkhcudLnTp1eDZeUFa0ydevXxUD1SwtLeHutmzZcvbs2cZneBsoApEVwFkOkfdSDx8+HBpH0Fbi7dxRVn4W8LYqpCQ2NpbrwYEbyd1URK+QSqUCkRUFDeTAiUMXwYgRI0aNGgVFlOgYlJUf5MGDB9xAtTdv3nA9OJ07dy5SpAhB9BjhWCuZMDU1tbOzmz59Ojz8QFbA2QdlFQxqohtQVjTg2bNnnJTAr4+PD0jJhAkTvL29CWIgCFZWOErJIfLr0Lx5c/Dp6miYJcpKDnz8+FExUM3NzQ2kpE+fPmvXrhWJcJ5ow0PgsqKgQoUK165dg14FWAZxqVGjRs2aNYn2wEusgoiICIWUmJmZga8E+u3AgLSxMZhZ/xCVoKwow42Watq06aZNm8qXLw9PSm2N6sZLnEZycrJioFpUVBQ3umTw4MEFCxYkiLFgWG8w80PZsmXB+qZpGny6tWvXnjJlSqtWrcjPIXRZefToESclL1684KRkwYIFRYsWJYgxgtZKdoCpAsb4xYsXr169Cqs3b950cHAoXbo0+SGEeIlBQTgpgV+w/UBKfvvtt2w/i4MYESgr6pFIJNAmggVXV9cZM2YMGzasVq1aRHOEcomDgoIUY16hXcO9iQPOKrHYkCY0R34SlJVc4unp+ffff4OTEZbHjx8P/Z49e/bM/e7GfIm/ffumGKgGNh5IScOGDSdPngwd+AQRJOhb0QhHR0f4hc6KHTt2JCYmwtVLSEjIjbfR2GQFzlwhJV++fOHGvA4YMMDFxYUgggetlR/A3t5+7NixRD7z6aBBgzp27AgVSv0uRnKJnz17dv36dZCSJ0+ecGNe586dW7x4cYIgSqCs/AxWVlYnT54MCAgg8k+jgAOhRYsWKmMawyX28/NbsWIF9I2NHDmyYsWKBEGyAVwGKCs/Sbly5eC3Zs2a8OQuUqSIypmVjeESh4eHg+N68ODBBEHU8uHDB2gmE+SnAbfLH3/8kd1WYxiBDs8fMG4JguQEFhUtEhISEhwcrHITygoiILCoaJETJ06Ah0XlJmNoBGFZQXIJFhUtAr2r2U2wj7KCCAgsKlqkdevW2W3CRhAiILCoaBH0rSAICxYVLYK+FQRhwaKiRdC3giAsWFS0CPpWEIQFi4oWQd8KgrBgUdEi6FtBEBYsKloEfSsIwoJFRYugbwVBWLCoaBEj962Ympria6lIbsCiokXQt4IgLFhUtAj6VhCEBYuKFlHjW6Gy0xv9Z8yYMVevXqUoiltVLDx8+JAgiBKNGzf+9u2bTCbjCgn80jRdsGDB06dPE+RHAd8KqIfKWaIN2LeyevVqDw8PUTqUnMKFC3/69IkgiBJNmzYFHRGLxcpFpV69egT5CdT4VgzbZfu///1P2dqC5Ro1aoCyEARRolu3btz3hhVAIenevTtBfgKwUwoVKqRyk2HLSs+ePT09PRWrUFa6dOlCECQj7u7uDRo0UA6pXr16JqFBNAV8K23atFG5ybBlBfSyUaNG3JcJwcqtVKmSl5cXQZAsgG2iKBtQbDp16kSQn8OYx61AcYFnEZGbKr/88gtBEFXkz5+/WbNm3BOofPnyJUuWJMjP8bPjVt4/TUmKT8oQBA71TD1IihBwtsv9HeAVy9TNpBQij8313WTqisomZeXUMkYRN67R90L8hbLFy4ji3Z4/iM2QYNbUlHKo9rjsetZTUBn5+5rKlCGLYtPiPhbEcIj8LAsPSwQLUL6Wdn5cTxujuHcMSb+JDHf+FHQsksy3/vvFEVGEZuT/UnSmYsCkpZoWwF56+QIjX0hLiGGfgrBKZ96Qtg9h01G+M5ny7VOibbVSYYlJSfV8ur24H/P9PimdggIGDkV/P5HMN5aiRGxGVBVdpeKquCDfNypl/Hv2VBUxERHRhM504PRTyYyFpcSjrITwi5pxKzl0MB9cHfQ1OBnOJjWFJupRIzRZQuTXlvrxdLKgLsGfIReHzg0mZiKGZixtTfrO8CD6zcW9X98ExMqkkF+GkaWphfJFUFxqRqmUUxk3Ke+i2Jr1YuZ415j0R0+GdDItK8XJvHum9DPkKsMmFYlkPussGc2ubGQIzxxJdW5z//BTkQ8WsSmoHONUyOKXsXrxUWB1srJvaRDoZY1WBfK7mRHkJ0khl/4NDfmQMHSJ/np/Hl2K8b0WVa6WQ6nqNgQxKL58Trl7MhyMqG6/uxFeUDNuJVtZ2TX/o0gsajecpywKhNePE++dDRmySB+V5fzuL+8C4rpPKUIQg+XohiAik/We7k50z+bNm+FX5ddEVbtsX/omJsZJUVO0TrFKFhbWJkc3hBD9401ATJ2OBQliyLQf7hofl/r6YSLRPWrGrah22T65FW1lzbcHSCC4eFh+fBVH9IznDxLBS+lW0pD8yohKrKxNA29/K1ZZ57dS4/lWEmJTiDgnHy3yQ0isRClJMqJnRH9J0o53GslzRHR8fArRPRqPW4F+H2kKyopOkDF0qv7N+CGjZalSlBVjAO5jKh+qYuzzrSAIkhE+nhBGPt8K8vNQFKWDYT9IHkCxb2jzISuaz2VLESxlAoNB34pxwNAMzYsDQ/N3ghhisLM7GQB6KNkMkzYAHjEC+ClgP+JbQVnRGRReXESH8NXU+BHfCjaCdAajj3YBhbaKkcDbfdTYt0KJiMgYPvWB5Kb+SCQAABAASURBVJYMrwQjBg4/xrDGvhWGJjQOWxESDEGPrZHA8OV8x3EreoU+9uViB7NxgeNWBAbD9broGYzhftgFyQj7fODlGWHk32A2LOQzIOmdZUCxg6gIYgSwzwc9HbdiICxYOH3U6IGERw4d3teoSTVidDDcfJB6z8n/jjRoVEXrXyZ8+/Y1JOvv/xiWZ82eOH7CsKxxsgv/YfoP7LL6j8VEF4VKb8etIMJC2INs8+Wz79N7kLOzuulm6tZtJJXq5B2+MqW9e/caRLQFX1Yn+lYQRB0ODo79+w1VH6dRw2ZEN5Qu7Q1/RFswPCmLGt+K1mTl48f323ds8vV7CAJWtmz5bl36lCtXEcLBXv1r24Y7d2+Eh4d6e1fs0K5LjRq1uV3evXtz/MTBR4/vh4YGe3p4tWzZvl3bzkRukQ78tduiBauXr5wPj5Gtm/dC4O3b1/9Yu+TLl/BiRUu0b9+lRfO2XCKmJqa+vg8XLJr+7VsUbBo1amIZtXeoY+em7dr+0rfPr7AcHf2tfcfG9es1njVzMbe1c5fmnTp2796t75Mn/jt3bX7+/IldPvuaNer07TPYysqKiwN9JsEhQdu2bbh776aTk3P3rn2bNm1Fco+xdLrExsXCHb9750bUt8iSJco0btyiVcv23KYzZ08cP3Ho3bvXRYoUa9igKVxS7pzj4uL+PfjPvfu3379/4+jgVKtWvQH9h5mbm8Omdh0a9ek16NqNS9ASOXb0kq2NLZSoFasWwKpLIdc6dRpCTDOztDmVIyK+zlswFe6Rm5t7t659FMdVybz5U6OiIleu2MSt9u3fGYrKsSMXFVvjE+IHDxoFRe6PVVvKl6+kvC8caOjw3mVKl5s9a8nsOZPi4mJXLN/48tXzIUN7zZm9FEoIlFVHR6cG9ZuOGD6O2yUyMmLDxpWBT/ySkpKqVq0JJ1W4sAe36f37t4uXzPrw8V3FilX6KJkn0AiCXS6ev0eyrxS5R2RCiXkpYD/yDWaNMpaSkjJm3GCxWLxk8doVyzaaiE2mTR8LlxU2rVm79OChPR3ad92z+0S9uo1mzZl49VraHV2/YcX9+7dH/zZp8aI1cPn+WLPkzt2bEG5qagq/u/7Z2rVL7/HjphO5psyYNWHggBEQs3btBkuXzb1w8QyXSFh4KNyGqVPmwaYUacqy5XPV92lUqVLj6bMAbhluXoECBQMCfbnVoODPUIwgwuegTxMmDk9KTlq3dvu8Ocvfvn01dtxg5fb8osUzmzRpNXfOcu+yFRYtmfXp0weSa9iXS/Ww10VzsVu6dM7TJ/5jxkzZse0gPGxXrV4E9RzC4dYsWTqnRPFSe/45PmjgCLj76zas4HY5fGTfnr074LYuXLB6yJDRV66eh5rJbYKbfvLUkWLFSi5but7SwjI0NGTkqP7lvCtCNe7atc/FS2egIHExTUxM1qxbCq0GUIpSpcqCeyIsLFRNPn18qj17HiiTsVNngb6EhbEzfn7+/JHbCne/SuXqKndMTEycOHkkyN+0qfOVrw4Ub/j955+/5s9befb0rRHDxx87/u9/p45CIBxl7Pgh8HAdO2bqtq377fM5DB/RF8oVbJJKpZOmjMqfvwBcriG//rZv/y4obFkPml2lyD10KiOT8VHANPatUCLw4GlQyqBewQ2DhxIUJliFh7+f/yOoh8nJyWfPnezRvV/bNuxH5Fq2aBcY6Lfr7y2gL7A6Y8aihIT4QgVZtatUscqZM8fv3b9Vo/r/uFtYtUqNXzr35NKHp2LdOg2bNG7BhcfHx8GO3KYvX8I2bfzbxpqdKb5jh27LV8yPiYm2s8uXXVZ9KlVdu24Z+w0XivLze1i/XpOjxw7AjXd1cQsIeAzGUfFiJXfs3AxGEAgKl86E8TO692xz4+YVsGuIvOjAgapXqwXLUA3gyXzx0tl+fQfn8loxejl4n9L87VK4xWApwO2A5cG/jqpXr7GdLXu5Tp06Cs/8MaMnw7K9vUP/vkOXLp/bq8cAWO7ySy+49R4eabNwQ2GAOz5k8G9ELmu2tnajRkzgNoEYSczNoWECzyq4ZWCnvHjxlNsE5aptm87c9QdvyIULp0E14PGQXT6rVK4BT7i3717DnYUK7+VV3NrKGjIPlg6IF9i/lX2qZ30UwV2eMXN8Qnz8xg27FFaSMmBAcUW3Qf0mFy6evnjxDBhNAQG+rJG1fCPkGTYNGzrm5q2rhw7t+W3UxGvXL4WHh/2xaiuXVQj5pWuLrMlmVymI/qGxb4WhNXuiwh2CCrl46ewmjVtWrFDZ27sCXBEIh6sMhkzVKjUVMWHr6TPHo6Hm29rBIQ4f3gdNCcXTvlAhV0XMEsVLcws0Tb95+6px4+/3YOiQ0YrlokVLcJoCcMUaypCdXbZZhTKUkJAApqaXVzF4Ug3oN+z5iyeBAb5yWfGt7MM65J888YPHoEKbChYs5OLi5h/wmJMVoHq1tNsMhy7iWTQkNIgYOD/wBjM0cg/8+w80JCuU9wFrv2QJ9n7BzQL7v0/vXxXRKlWqCoFw9UBQwCS5/+A2NARev3nJWX+gNYqY0JJSLIOFWLx4Ke4jhEDzZm3gT7EVjsgt5LOzh9/kpCQ1+YRq7CK/uSArcMfBwLSwsADDClTA3/8RNGGKFCkKbRlFfEoOSCEUjI3rd0HBVpkspKZYdnUpDMpC5LYPnCOnKVxSUOBBwmA5KOgTNPegLHGb4LjOzgVUpKu2UugVmvtWNHzxTCKRQLsU7EB4yIAnBe5ivz6DmzRpCW1R2Jq1DzgqMgIq5OSpo8G1/uugkdDUhNVM0cwkaXN0g0xAuZRIzFUeGkzi77nOhR2fP78ztHWh6MN9BXGBQg/POigNzZq1hqIPj1/CugBin794Cj2OmfKsWLa0tFQsm1tYgH1ENEAfXSuU5o2gSRNnHz9+8NLlsyAu8Pzv0KErqAmIBVj7UAbgTzkyGLPwu3nLWrBloPkDTxqo7Vv/Wn/q9DFFHGWjAAzS7OozUbrpucw01HN4VHTs0BXsU7CAoCxB4wLC4Y5XSpcABfAE5mxtKJPZlTrA3NxCadkcMkzkJQdOP1PJ4U4EComFhaVyeNbEoZyrrxR6hRrfSjayovk4UHd3TzD54J49enQP7JGFi2d6eHo5OuWHTePHTXN1LawcGWxX8HuBQ3T5sg2cgUDktyS/k3PWlEGzRCIRd9u0AhwR3Ctws8FgAYEoV67Sxk2r4KkL7W3wzkIEB0cneBRn6hrgTCEOUDrO0QiwJqtGzxOK6OHLwozmw2zBq9qr54CePfpDW+b6jct///OXtbUNNHPgkjZt0qquvJ2rwKWQGxzgxMlDnTv1aN2qAxfIPXVUYmVlHZ/ezv15Kleu/ueff8AtBqvEp1I1MIKCgz/DKjxOenTrp/Los2cuAYcxGFbQolEpXsqZl5cHVmXgWQWm0IL5q5RjikWszQVNvMTEBOXwhCwnmPtKoQbILMXLcDTwrRCNvhOkKdCeBCkhctmuVasuuM3hefLy5TM3V3eJ3OiANhH3B85tD/ciUPLgpkK44pKBkxz+VCYOhaBkyTIKxyqwZeu69RtWkh8FfHj+fo+gi6FChcqwCn5ByD800UEZoaMRQop6FYd+K7C0FdkG3xtsVaTw6tVzbgHaUx8+vAMbmOQeRh9H2Wo6SUd8fPzhI/uhOkGVAwkePmwsXKWX8ssCzVLoJFJcOmh0gNcTDH54jIMT1Cn9jkPr+Nbta9mlD3cc7AuFmxy8VxN+H865XX8AyEZoWAgkUrRocSh7UCYhfbjjcN+ryH1DmYACULFi5TmzlkKp271nu8o0wU2jWH79+oVXkWLcucM5wlNTcfoFChQqJm8uFSxQiHXxpLe2Xr9++fXrl0xp5r5SqIFtz/IyylbNd4KymRhBw5mGwMCD3pmNm1ZDHwq0CeFOQIGA8gS3sF/fIeCj5Zws0AcEPSzcyELQF5Ce/Qf+jomNgbsLblRw/oWGqf4uV7s2ncE9DpEf+z44dvzg3n07oT1MfpRKFavCgW7fvgY5JPIWDbSToZOicnqPQOfOPcEchf4LKAdwOn9uXjNgUFfw+XFbIdvgQoY8s33n2zfAL/ShEg3Qx3eCKA0nlwKth06c2XMngakCXarnzv336vVzEGjY9OvAkTdvXoHWDVxDuO9z500ZN2Eo3H1o44A0w+MnSG4pgPMC4sfGxoBCZU0fHB+wy8pVCx88vAum0Jata8HyVbhaNAXcZNCZAK5T7o4DsAB3HMxVsC+y2wu2QmNkx84/X6Y/RZQBJ9Hde7dgAXz5UCw53x9YGdWq1Vq+fB50TsE5Hj3279Bhvc/In7jQmw5XYPnK+VCoQFDmzp8C9kumNDWqFHkO+FbatGmjclM2LltGs2cX+GjHjZ0KNwCa2YT1vVeHzj9PT/aToOCtAAnfs28HNI7Atixbpvz48WyfMTStod8Oima79g2hiTRtyryIyK8zZk7o27/zgnmZLRFwfMTERkNkKIJQDqDfATqVyI9ibW0NDyuwNhWutbJlyx85ekCxCub9X1v379u3c8iwXnB3wX37+4QZXCeXTJZqaWkFpj50qIO/AEre9GkLwGNNDBx5G0iDWw5m6dzZy9auX8Y1/kHlhw4Zww0mAuNl86bd8GgBOU5KSoQ7Dh2xnNE6Y9pC6EDt178z7D582DhwH9y7d6tDp8Y7dxzKlD5cUuhhhfoJMgT7NmvaetCgkeQnAB8KVFdo8HKrcMfBDwh9l+r3ghsNOZw9eyKUh0yboPX011/rJ0/5DVroHTt2U4ydWbRg9fETh0A1nj4NAC8eyA1sJfJSB93qmzevad22Hpz+4F9/47y8yqipFDu3HyS5J6/Hraj+BvPOee9pmnQe40kQbfPw4tfAG9EjV/64taULbv339dHF6L6z9CtX+gk3XDPr2Dk94eDq9yIR6TvDk+gYNd9gxsH7vINTmyC6RCSi+JnaUeNxK5SIIgY7Oxy056dOG5Pd1n/+PqpmsBwPUDgRmw5o07Z+dpsmTZpd+3/1iWBgh9jyMoz7B94JYiiDnTKBbdtv3pPd1rzVFMKNstXD+VYMfPZiNXccevGIVgGH2uWLD4i+wts0ThqPW4EOKsaQ57Llxj4jucfQZy/GO84/asatqJYVaJ4RRGfgXLaIEaD5O0E4taku0cNrizfcaJC3Z/VyLlsGP5aqQ9jBhgRBdAMl/+gT0T1GO5etYaKXEyNgI8hYoGmGH8cozmWL5ARD6+ErBYg+o/m4FXxy6RB9NAwY/XyxGtEc9g1m/fxOEDpWdAteX0RnyB2j6FsRHProW0EQTUHfCoIgWkZj34qJmRjtdB1hYiIyMSP6hkgs1sNcIT+AmblIJNZL34q1rVgmRV3RCfHRMjOzH5yOSHc4FTDXxznrEM1JTWEsrPgoYBr7VnzqOyXG/eAEf4h6Qt4mOntYED2jWCUL6D54+ziRIAZOUrzMp54j0T1qfCuqZaVwaTMbB9Oj6z4RRKs8vhAtTZIAAfY7AAAQAElEQVS1HliA6B+lq9vdOx9KEEPm+LrP1vam7mUkRPeomcuWUtMXdWxjcESItHxdh5JVbQjyc3z9kHL33JfYqJRfFxQh+sqbgMQLu8OKV7St2kLLkwkguubFgxj/a1FOhSRthxYkeQ2lvov7xObQ4HcJ4GehZdmOB2ayf8mFZigRxeR+l+zCafb9KSb7xCluYiSVU/BmzUPWo9DsNw6/uxZUZIOhiFIiTE7v9WQ6qMgEVkV2jqbdJ2kyR39ecP9cjP/1iOQkmpGRHAeBM7l4vynHeZFpwojU9rjLv0DJ/EgGMt61XB4020KbzYlkF6660Ko6bjbfYqeyTveV3fmKTERiE5FLEcs2g/kzhDWeyzYTiYkkRdnVonS+DMVepgxpUOnXiUmPqHx9qPRrk2kX8n2v78GKaOnhiogZUhWRUSNGzZgxo4Czc4bjKOdBOWPke2qMyuMrHY6hMmeMXRSRDLPnURnzlOVlL7FYbG1oj/+4Lzl/PiPLjc0pkspN7MWicnuY3B5Vdcxr168G+AeOGDECyi2VzUEzJJmbY2UJTzstVd8yUH1cKmuZzuZw2eTBzFpswbu/7mfnsoUcW1joXeeFMl9j3tvlF9vm1+tMGhbWxngxZaIY2iTGDsuJNtB43IrBkZqaqvzVVARRCZYTLaLxuBWDQyqVmpqaEgRRC5YTLWL87wThUwjJDVhOtIjxvxMExQWfQkiOoLWiRYzftyKTyUQG/UEKhBdomsZyoi2M3LdCyz9FgcUFyRFsBGkRI/etYFlBcgkWFS1i5L4VLCtILsGiokWM3LeCfjgkl2BR0SJG7lvBRxCSS7CoaBH0rSAICxYVLYK+FQRhwaKiRdC3giAsOGxSi6BvBUFYsKhoEfStIAgLFhUtgr4VBGHBoqJFjNy3gg1mJJeAGw5lRVugbwVBWLCoaBH0rSAICxYVLYK+FQRhwaKiRYx/3AqWFSQ34BAnLYK+FQRhwaKiRYzct1K4cOG3b98uWbLk6tWrycnJBEGywcvLSyLh40OiRg/Yfb///vvHjx9Vbs3V58f0HxDOGzdu3Llz5+7du6VKlapevXqNGjXKlStHEESJzp07L1++3NPTkyA/yrlz56B+URT19OlTqGUq4xiJrCjj5+d3R86bN29qyIGr4OrqShDB061bt/nz5xcrVowgP8S0adNAMebNmycWq/uEmxHKioKEhATOfgFgldMX+LXg/7uSiH7Qq1ev6dOngz1LkFwjk8m2bNlia2vbo0ePb9++5cuXL8ddjNl9ZWlp2VAOLH/+/Bkk5tSpUzNnzixevDgnMRUqVCCIkAB/LXhtCZI7wsLCChQocPHiRbhuYOhBSG40hRi3tZId/v7+nBXz4sULRSsJ/L4EMXYGDRo0cuTIihUrEiQnwCMLdsrKlSuJ5gixs628nMGDByclJXFemN27d9M0zekLYGVlRRBjBK2VHLl+/Tq4tOEp27JlywYNGpAfQojWikqCgoI4LwyoDHRDcl4YfKwZGWCqgHslu/4LZM2aNe/evVu4cOFP+h9RVlQQEBDA6cvz5885+wUKoru7O0EMnDFjxkAfc+3atQmixM6dOxMTE4cOHRoREeHo6Eh+GhxxqIJycqAdnpyczOnLvn37pFKpwhFjbW1NEAMEG0HKREVF2dvb37t3LyYmBnwCEKIVTSForeSekJAQzhEDQgONT86K8fHxIYjhMHny5MZyiOBZtmzZo0eP9u7dS3QAysqP8OTJE05fAgMDFcNhPDw8CKLfTJ8+HVpAzZs3J0Ll/v37tra2JUuWvHTpEjf2QhegrPwUKSkpihF30K/E6QtgY2NDEP1jzpw5YGC2adOGCJI9e/ZAR8/ixYvt7OyILkFZ0RqhoaGcIwaA/jnOiqlcuTJB9IYFCxaUKVOmQ4cOREhASwc6OidMmBAeHu7s7Ex0D7pstUbBggXbyYHlp0+fgrhs3rzZz89P4egtUqQIQfIUQbls4+PjraysXr58GRwczHlk+dEUgtaKroFCrHD0JiQkKEbc6doKRVSyYsUKFxeX7t27E2Nn27Zt0G189epVkhegtaJb4PFYWw6Rv2EB4gJ3esmSJVC4OUdMlSpVCMIXRm+t+Pv7S6VSaHpDZ2VeaQpBayWvePbsGeeI8fX1VYy48/LyIoguWb9+vaWlZf/+/Ykxcu7cuX379i1atKhAgQIkT0FZyWNkMpnC0RsbG6twxOTyVVEkN7Ro0YLIJzSDdihN09wy9LNevnyZGD5Hjx4FI2XmzJm8eWRzBBtBeYxYLK4lB5a/fPkC4nLt2rVly5aBA5izYqpVq0aQn6N48eLQsZpp5iFDH8IP+picnJyYmBgYGDhkyBDCo0c2R9Ba0VNevHjBOXofPHigGHFXtGhRgmgOVLyxY8dGRUUpQvLnzw/a7e3tTQyTI0eOQGPnypUrFhYWFEURPQNlRd+Bh5JixN23b98UI+7s7e0JkmumTJly/vx5xWr9+vWXL19ODI1Xr15BS+d///sfNN9+eNYCHkBZMSS+fv2qcMTA85bTF2wl5QaokKNHj4Y6CcvQu7948eKqVasSgwLsVuggByNF/6f4RlkxVF6+fMlZMffu3eNMGPgFJwJBsmHevHnHjh2DBejU37RpEzEQzpw5A+62hQsXwkPFycmJGAIoK8aAYsRdZGSkYsSdtl5yNxqCgoKGDRsWHx8/Z84cg/DXcvNRT58+/ddffzWsF1lRVoyKiIgIxRx3Dg4OCkeMysjQeqpTpw7Y1ZnC/a/HPjgfmZwkk6XSJEvxYAh4CLMGEpVuQ9WR5aG5jCxPWEURpQklIqqLLsOAE5PJfTibGkOJqOxSI2pcojltzfaIaRGyuW7fNzEUoXKooWITkalE5Fbcqnlf7AlCdAx4Ezh9gV9QEE5iSpQowW1t27ZtcHAw3H3oDdm5c6dir5e+CVf2hRUubV2muoOZBOpb5mQVNQFKO0NlCc0kA6o0Ibu6pFo/soSmHVcRniVCdjWRphgRQ6lOVk39Vo6Z9VjZ78flRMQQNRWM2z3Dlcx4FPXpc4ho0evAb6/9Yiysxd3GuxE9AGVFEID/hWsoffnyhbNfVq5cGR0dTeQ9TW5ublu3bnV2dr6458u7wISukwzJ3kYUHF772dyc6Toh778hgbIiLKKiojh9OXHihEiU9gVuUJZChQotW7bs6g7z5v3dnFzMCGKY7F38rkZzx/L1bEmegrIiUHx8fBSywvG/0gPKuDXvMRnfSzJgTm4OAm9Otwl53BTCwftCBBwrnKaAnQJORWtra/Dv2lq4sp4AxJCxsBJFhSeTvAZlRYjExMS4urpaWVmBoLi7u5cuXRp+P95xCv9EE8SQSUlJTUnO+2cDyooQuXLlyv3794sUKaI8vCrk0WdC8v5BhxgBKCsCxeCGriMGBMoKkobIVGxiqnfvwiKaoR9vM6OsIGnQUlmqFF22Bo5+dOyirCCIESHK4XUBfkBZQRAjgmYYJu/bQSgrSBom6FtBtATKCpJGKvpWDB9KpBdTUKKsIIjxwDB68TYOygqSBgXuPoIYOIzq6SV4BmUFSYNRMbkKYnDkZoYWnYOygqQj0r8PQyCaoh++FRFBEA4a58jQFW/fvm7QqIq//2Oia2i98K2grCBpsJ0I6F3RHu/evenWozW3nC+ffZ/eg5ydCxJhgI0gJA0GHnToXdEeL14+VSw7ODj27zeUCAa0VpAfJy4ubvuOTcNG9G3Rqnav3u03bFyVlJTEbWrfsfGx4wd3/b21UZNqrdvWmzN3ckTEV27Tx4/vYbVDpyYQZ9qMcQEBvhDYsXPTnbu2cBGio79BkwHiKA7UuUvzvfvYebyfPPGfOGlk23YNevftCIeLj4/nIhw6vK/TL81u3LwCh1u7PofPFb5//3bosN6Nm1aHZKFhMmr0wBUrF0D4vv274EQU0cLCQiEbN29e5VazO3RsXOyadct69mrXsnWdseOG/HfqKATCZVmydA6Xwr8Hd2dqBEGag4f0bNaiVpduLadOHwvRuHA45bnzpty6da1t+4ZNmtUYPfbXZ88CiSZQIr3wkKGsIOmIRZRYsyJ5+Mi+PXt3dO3Se+GC1UOGjL5y9fzOXZu5Taampvv37xKJREePXNy5/VBAoO+OnX8Sdp6hlDHjBovF4iWL165YttFEbDJt+lgQoypVajx9FsDt++jx/QIFCsIu3GpQ8GeQJIjwOejThInDk5KT1q3dPm/O8rdvX40dNzg1NRXimJmZJSTEHz9+cMrkuR3adVGTZ5lMNmnKKHsHx727TyxdvG7fgV2fPn2A3Ko9UaLm0EuXznn6xH/MmCk7th0sXdp71epFIEBgm3Tr2gfO4vLFB7907qmc1IOHd2fO/r1p01YH9p2aNWNxWFjI6jWLuU0mJiZPnvqfv3Bq08a/T/93Q2ImWbRkFtEMvbA3UVaQdGQ0I9OsUHb5pdfWzXvr12tcqWKVOrUbNKjf9N79W4qtrq6Fe/UcYGNt4+joVLVKzZcvn0Eg1OGoqMhOHbuXKF6qaNHis2YunjNnGdRPn0pVAwN9OX+jn9/D+vWaxMXFgqDAakDAY/BNFC9W8sKF06YmplCr3d09PT29Joyf8er1C7BQCDsfAAXa1K1b38aNmru5uavJM9Tq8PCwwYNG5c/v7OVVbPSoSWAc5ejnVHNoP/9Hdes2qlqlhrNzgcG/jlq/boejY341SW3bvrFunYadO/Wws8tXtmz54cPG3blz4/mLtBZTYkLC7xNmuhRyBYlp1LA5XK6EhASSaxh02SJ6BdjPIg1dtvCQv//g9rDhfcBiByP/wL//gGQotpYoUVqxbGNjGx8fBwtQ50EjFi+d/c/ubYGBfnBIkCRra+vKPtWh/oCbE+KAnVLOu2KpUmUD5e0jaCVV9mG/M/3kiR8EQm3k0ixYsJCLi5t/wPfulVIly+aY5zdvXpqbmxcpUpRbBYMC5CDHuqjm0OXKVYQT37hpNTRepFJpyRKlYauapMDSgaQUqyVLlIHf58+fcKuF3T0tLS25ZWtrG/iNjY0huYYhlD7MjYAuWyQNhgY0K5Gbt6w9deooNH/AGIH6ufWv9adOH1NsVTmCQiKR/LFqCzggDh7a89e2DVA5+/UZ3KRJS7AdChf2CHziB6YNiEulSlWfPQ8EfWnWrDXUXmhQENaVEwtPddAv5QSjIiMUy9AUIjkBwmdhYakcYm5ukeNeag49aeJsaHxdunwWxMXayrpDh659ev8KtkY26cQlJydLJOaKEE5EoAXHrWb6HIKmUITRh5mcUFaQHwSe8CdOHgJjvnWrDlwI1L3c7AjtiGFDx4D34dGje6fPHF+4eKaHpxe0icAkAfcK2DLQNoHKVq5cpY2bVkEL5fPnjzVr1IEdHRydwDTI1KViZ5uPaALYTSkpGabsTUxU3cqQ0TLFsppD29rYQluvZ4/+YHxdv3H573/+AisDmocq0wRDCX6TkhIVIfFyQXF00NI320V6WBTI9QAAEABJREFUMT8cygqShgjcpyYaFElwiCQmJjo5pX33F3yxt25fy3Ev6AYCr2SL5m2hgtWqVbd69f81b/k/cLuArPj4VNu4cZW1lU2FCpUhJrSDIDI4NUCGoIMWQop6FT93/r8K5b9/4Qj6dNR7UrJSqKALdOJAypAskfuDv3wJ5zaZmpqBKQHnxdkaHz+8U+yV3aGjY6IvXjzTskU7OB3QHfh7/frFy1fPszs6pAytJPDpKkK4Za+ixYl20IuRR+hbQdKgU2WpqRo0gsCxAjUTzA2omWBTLF0+F4QAHAGKnleVxMREL102FzwR0LcC/sjde7ZDNfYuWwE2VapYNTQs5Pbta9wqGCzgpoXOpsqVq3P7du7cE9pp6zasAO8s7Pvn5jUDBnV9++410YSaNetCW2nZinmQCLhdFy2eCZ4dblOZMuXABDtz9gSR9y7v2bdDsVd2hwYphs6v2XMngakSGRlx7tx/r14/h+tA5F4k6MC6ceMKxFfOQIf2XcHXe+jQ3pjYmMe+DzZsXAnuajhTohXQZYvoFWITkVjDDuYZ0xaaS8z79e/cq097aMIMGjQSVjt0ahwSGpzdLt7eFcaNnXrh4unefTr06dcJenlWrtgEfSuE9VBalyxZJjgkCKoZFxk6SpRXobnx19b9FuYWQ4b1gn19/R7+PmEGmDlEE+AoC+avSkpMbN223pChvaBTRmFwlS5VFlpnmzevAR/K3PlTBvYfTuRtPTWHtrKymjt72dev4aNGD+z0SzPorh46ZEyb1h1hlxrVa4O+zJg14eKls8oZgK7lgQOG7//373btGy5ZOrt8uUozZywixgV+LBVJ4/ifn4PeJPeaVpQIjP4Du0DrZszoycTwOb39U1RY6pBFRUiegr4VJI0f6GBG9A2cHQ7RM4zlnaA9e3fs3btD5Sboclq3ZhtBdAzKCpIGPOiMw1rp1LF7mzadVG6iVHWUbP/rADEW9GSULcoKkgb0dMiMwlqRyCHCRMT6S0leg7KCpCEWa9wThOgdNDedbR6DsoKkIZPRMhl2Cxo4+A1mRK/4gXEriP6B32BG9AlZKqFxdjhDRz9uIMoKkgb7gRlUFUQboKwgaYhMCDaCDB2KwuFwiD4hS0WXrcGDH0tF9AscvI9oC3yDGUlDZEJRYoIYNGJTzSbN0REoK0gallZmPznjIZLnMDJibpn3DwcsRkga/2vmmJIkI4ghE/0lpZBXzlPz6hqUFSQNMzvikF9ybFMQQQyTR2di6VTSsKuWpsX9CXAaJyQDR9YHx4TLWg8pbGZFEAPi6oHw4Dfxgxfn8QROHCgrSGb+/SP46+dE8PylprIvCqmPTKn6Lk3mQCqH0Z8QnyaMiC2NGhzl+yaS69Gl6TnhBndodDhKvi+T6/jQrZa1u1d1ykrZV0SgKBV1U+XupmZimqYtrEz7zdJstnDdgbKCqMb3UkxCvFQmy8nbkmNFyaaGZN6BkbfIs4mmLgX5+C+16X/PTXBIcMTXyHLlvNOmXsn2cCKGoVXlkVKtfKovgoh9oZjJLi/Z7J6+TLETHGSRFVWBEolpmer21g5Ef8BxK4hqKja0JUbHsWO3I77612nfkCC6BK0VREBEREQkJia6ubkRRJegrCAIomWwgxkREOfPnz9wwHhmrtVb0LeCCIjg4OCYmBiC6BhsBCECIiwsDAp8wYIFCaJLUFYQBNEy6FtBBMShQ4fOnDlDEB2DsoIIiI8fP0IfM0F0DDaCEAERFBQkkUicnPL+ZTzjBmUFQRAtg40gREDs2LHjxo0bBNExKCuIgHj37l10dDRBdAw2ghAB8eHDB1tbW3t7e4LoEpQVBEG0DDaCEAGxbt06Pz8/gugYlBVEQLx8+TI+Pp4gOgYbQYiAePPmTYECBaytrQmiS1BWEATRMtgIQgTE4sWLwWAhiI7B+VYQAfH06dPk5GSC6BhsBCEC4sWLFx4eHubm5gTRJSgrCIJoGfStIAJi5cqV4eHhBNExKCuIgLh161ZCQgJBdAw2ghABgb4VfkBZQRBEy2AjCBEQCxYseP/+PUF0DI5bQQQEzrfCD9gIQgQEvhPEDygrCIJoGfStIAJi1apV/v7+BNEx6FtBBMTnz5+joqIIomOwEYQIiI8fP9rJIYguQVlBEETLoG8FERBbtmy5desWQXQMygoiIEJDQ798+UIQHYONIERABAcHm5ubOzg4EESXoKwgCKJlsBGECIh9+/adO3eOIDoGx60gAgIcKziXLQ9gIwgxflq3bk3TNCzAL0VRJiYmjJz//vuPIDoArRXE+ClUqNDDhw9Fou9NftCXmjVrEkQ3oG8FMX4GDBjg5OSkHGJtbd29e3eC6AaUFcT4AcOkbNmyyiFeXl61a9cmiG5AWUEEQe/eve3t7bllKyurnj17EkRnoKwggsBHDrfs7u7epEkTgugMlBVEKPTr169gwYJmZmZdu3YliC7BDmYkt9w8HvnaPy4lUZacJMu0iSJQjKDrlmQtTRQhEJa2iVtRFSFtOT0FSr7KqDqKIhqlIoJSUhm3yncjMpqBPZW7hLJNSh4kzzLFKG1UismkZzNX+fmejfRAKusCHInKkDFlzExFJhKRs7tF64EFiH6DsoLkihObQ8I+JDm5WToUNEtJkWbaCooCBUlEUTSjXAOptIopryxMerRM+4oIRafXPkUEkbxW0ZkPIyLysPQDsalm3P17VcyaGW4rk7Gmc9EyaUdaOPwjV0ui4qQynIvymSpvyposewokPb/pKX+PpnQsEUXojLuaSkwTolPD3yekSOlf5xchegzKCpIz/yz8lJrKdBrtThA94N6pb6/9I4cs8iL6CvpWkBy4eTwiMSEVNUV/qNYyn52TZO/Sz0RfQVlBcuC1X3wBNyuC6BPVm+SP/ppC9BWUFSQHkhNl+ZxNCaJPOHmYMTQTF0n0E5QVJAekSTQtkxFEz5DJ4Lbo6X3BVw0RBNEyKCsIgmgZlBUkB9iRFiKKIPoGxY7E0U9QVpAcYAeg0Ti4Sf9g9HfMGcoKgiBaBmUFQRAtg7KC5ADbgEffiv7BcG4vvQRlBckBBjQFVUX/oDi3l16CsoLkhIxh/xAk16CsIIhBIp/OgegnKCtITlCcfwXRL6gsc7noDygrSE4whOCkPPqI/oo9vmqI5IC8J4gYEIcO72vUpBrhl7w4qP6KPcoKkgsMylgpU9q7d69BOUY7cvTAoiWziJbI5UEFAjaCkBxgn4kGJSulS3vDX47RXrx4SrRHLg+qRRhsBCGC4s7dm2PHDWnRqnbP3u3BIoiI+MqF3759fcHC6V27t4JN48YPfez7AALj4+ObNKvxz+5tit1lMlmrNnU3b1kLy5GREfMXTOvWo3X7jo0XLJrx6dOHHI+u3B6BvY4dP7jr760Q0rptvTlzJ3OZGTNu8NlzJ8+d+69BoyovXz2HkDNnTwwf2Q8yBr8HD+1RvG8za/bEufOm/Ll5DcTctn0T/AYG+imO9ez5EwiB81U+aGpqKsTvP7ALnMWkKb/duXODC+/YuenOXVu45ejob7Aj5EeRVOcuzS9fOU9yDTc/uH6CsoLkBMXOqZ/76FBLp0wdXalS1R3bDv42auKbNy+XLJ0N4UlJSQsWTU9OTp48ac7CBavd3T2nTR8LqmFlZVWzRp3r1y8pUnjw8G5CQkKjhs1BX8aOH+Lr93DsmKnbtu63z+cwfETfoGAN5nA1NTXdv3+XSCQ6euTizu2HAgJ9d+z8E8JXr9wMxkXTpq0uX3xQonipCxfPLFk6Bxb2/HN80MARICvrNqxQpPD23Wv4WzBvZbu2nW2sba4pZfXGjcsQUrVKDeWDrlm7FFLo0L7rnt0n6tVtNGvOxKvXLkJ4lSo1nj4L4OI8eny/QIGCkB9uFU4K9K5EidJEAxiir8PhUFaQHKFEmjSCAgN8zc3Ne/UcANWmerVaK5Zt7N69H4RD4NbN+8aPm1apYhX4GzpkTGJiIlev6tVrDGIUEhrMpQB11dPTq2jR4gEBvh8/vp86ZR6k4+DgOGzoGFu7fIcO7SGa4OpaGDIDld/R0alqlZovXz7LGufUqaPly1caM3qyvb2DT6Wq/fsOPXr0QFQUO6cjRVGhocFzZi2tVasupNCgQdNr1y8qdgSJadSouVgsVoSAboId1KN7v7ZtOtnZ2rVs0Q70cdffrJECKQcG+nJ2kJ/fw/r1msTFxXIqGRDwOF8+e1cXN2IUoKwgWsa7XEUwTKZMG/Pvwd2fgz7Z2eUDEeE2JSTEr123DKx9sP+huQEh375Fwe//atWTSCScwQK1Dp7tUBVhGUQHjAWojdzuUMMrVqjs5/+IaIKyCWBjYxsfH5cpAk3TgU/8QHEUIWBqQaB/wGNu1cO9CGgit1y/fpOwsFCu3fTu3ZvPnz9yWVUAspWSkqKcGuT57dvX0THRlX2qgxUGe3GnVs67YqlSZUGF2dUA38o+fPde6Q502SI5wX4IUANzBZoSixetuXbtIjhHNmxcBbWlX98h3t4VoDaOHjvIp1K1GdMWlilTDjQCXCrcLlBpa9Wse/3G5S6/9IIKFhsb06RxSwiHh7lUKgUNUk4fnupEE3Kc7AhUAI7y17YN8KcczlkrgJlEoggEjQCLBs4OThMynD+/M5ya8l6QZ/gdNXpgpqNERUaACVa4sAdIGFg9IC4gXs+eB4K+NGvWGiSsW9c+RBP02WWLsoJoH2izwF//fkMfPrx76PDeqdPGHD50/srV81CBwbFiYWFB0u0UBWAFgHMU/AvQrChbtjw0oCAQqh9EXjB/lXJMsUhMtAqImqWlZdMmrerWbaQc7lJIRZMERAraQTduXgEXDDTWOPlTxtEpP/xCWw8aX8rhzs7sGYHIgnsFlNHLqxgctFy5Shs3rQL3LVg94GAimgCaQov0tIsOZQXJAXgmavQCvq/vw+SUZJAVJ6f88BwuWNAFul1Cw0JiYqKhDcJpCsB5MRVApQLf7Z27Ny5dPqsYAFK0aAnwv0CFVDgdgkOC8tlpZq3kBjhQbFysorEGxktISJCzs+pPHTes3/Tw4X3Qv/Pq9Qvw+2Ta6ubqLpFbN4rUwOoBcw9EBJZ9fKpt3LjK2sqmQoXKsArtIHAeXbhwGhzY4DwimsFQtJ7aK+hbQXJA07kNwcifPWfiiZOHwR55+izw8JF9oC8FCxTy8ioOxsjxE4eg//XuvVuPHt0Dt0t4eCi3F/hQatWqd/z4QXh016/XmAuEZ3u1arWWL58HDSgIP3rs36HDep85c5xoA7Amnj0LhB4ZqPa/Dhx58+aVU6ePgUsFWmHQozxuwlCwrVTuCMYUKM72HZvA4oB2TaatIB/Q6AMfLaQDKYB6Tpg4fPUfi7mtlSpWBYW9ffuad9kKXOTixUrCJapcuToxIlBWkBxgZ2LWRFfAP9KqZYd165d36NRk7LjBlpZWq1ZuNjExadSwWe9eA6G+gUsFenOg7xlaEHv27li5aiG3Y/26bH8QSAk4L8892ngAABAASURBVBSpLVqwGvqJ5s6f0r5jY6h+jRu36NixG9EGbVp1hDP7feKIN29flStXcfOm3f7+jyHPoALg1p0/b6VEyaWSCejEgaw2bNBM5Vbwkvw+YeaefTvatKv/x5ol0JgaP346t8na2rpkyTJgcyn80CBSyqvGAX7aHcmB9ePelK1pV7mpE0H0iR2zX/eZVsTOScueJq2AvhUkJ3BSBL2EAt8K0VNQVpCc0D9zdsq0Mdxwj6y0bNl+2NAxRBjgBz0QQ4USU5SeGdrQS50qlarcJJGYEySvQVlBcoCRMYyefUHcztaOIHoMygqSA+xYTnSvIJqAsoLkgMHNtyIQ2HuCU2QjBgpaK/oJRXDmfcRwETEUftVQH9Hf+VZQVpAcYGhKb7+eh+gnKCsIgmgZlBUkJ/A7QYiGoKwgOWBw3wlC8hyUFSQHGHYyW9QVPUR//egoK0gOmFmIZSnYE6R3iExE1nb6+PoyQesWyRFrO5PwT4kE0See3I41NaHEZkQ/QVlBcqBFH7eosCSC6BMBNyI8y1gRfQWncUJyJuh14oktIY17uRVw19fno5A4+McHt6IWTXo6E30FZQXJFffPRD+8/FVkKpaYUymJGcoMJaYZWQazl2KLFduDlDEek2XiIYad0FIeiRIRxaA7htBUFjtaPvMllbW0Zh8uT4pJW/4egYJMUNmUeobzg2aInzGfWQ4j34XJugv70TYmmyms2e+50apn8hSJCZ3N++ImZoSRkeREOr+reecxLkSPQVlBNODmkW/hwQnJCRnmOgHfIZ2acRyumCI0qysZhueCUGSMxdZvKi2QEhPF9AvyOpylWIpZAWFoTie+KxYlZmt1WrgSbDhJm9IBlhkZGyEpKSlZmpLPzi5rfHkO2Wyz8UWUcgT2S0OibGaHEMnVk2Yy7SJPRMTQqocns1cMIqvKg8iUoqWqq6SpuYmtvWnDNs5ivZ8WAmUFERDHjx/39fWdOXMmQXQJdjAjAiI1NdXEBMu8zsFLjAgIkBVTU1OC6BiUFURAoLXCD3iJEQGBssIPeIkRAYGywg94iREBAbIiFuvpezTGBA7eRwSEVCpFly0PoLWCCAhsBPEDXmJEQKCs8ANeYkRAoKzwA15iRECgb4UfUFYQAYHWCj/gJUYEBMoKP+AlRgQEygo/4CVGBATKCj/gJUYEBLps+QFlBREQaK3wA15iRECgrPADXmJEQMhkMpQVHsBLjAgI8K2grPAAXmJEQGAjiB/wEiMCAmWFH/ASIwLCzMwMO5h5AGUFERAJCQn4YSweQFlBBAS0gKAdRBAdg7KCCAiUFX5AWUEEBMoKP6CsIAICZYUfUFYQAYGywg8oK4iAQFnhB5QVRECgrPADygoiIFBW+AFlBREQKCv8gLKCCAiUFX5AWUEEBMoKP6CsIAICZYUfUFYQAYGywg8oK4iAQFnhB5QVRECgrPADygoiIFBW+IHCWW0Qo6dTp05EPuNkTEwMRVFWVlY0TUPJP3XqFEF0AForiPEjkUhevnypWAVxAVnx9vYmiG4QEQQxdnr06GFhYaEcYmNj07VrV4LoBpQVxPhp3bp10aJFlUMKFizYqlUrgugGlBVEEIDBYmdnxy1Dm6hz584E0RkoK4ggaNq0qZeXF7fs6uravn17gugMlBVEKPTr1w8MFpFI1LJlS/xakE7BDmbkpzi1PSwiNDk5nlYOpESEyRBARCJC04SiGHmRk8ehSKaipwih2FJJsXuJCS1TkY7SPgx0GHPHUj5olmg0YUSQfmxsHE3LbG1tIUhlVhkCB6ay5k1lZEU+ITH4R+Uu33NCydNWSiTrVVJGYkFZ2prVbuNQwFNCDA2UFeQH+fw68eSWEIml2NrOLCUpRXmTSETRNJM1hIKaRNHZViq2anKbQCnYJZGYomUZ0sm8l1wDuMjKm7JEY3VCqT6n7ZJpmYVVFYaIKEKrqBeZIn9fVScraZci/eS+75X50BmRWJomxsvio6Re5ayb9nYmBgXKCvIjPL8Xf/VQWNvhXtb5CKJT9i97X8jLvNWAgsRwQN8K8iNcPhTWcpAHagoPdP3dM/hV4sPzMcRwQFlBNObMznCJhSifs5ggvODsYfnkzjdiOKCsIBoTGZ5saYM9Kfzh4mGVEG9Ib0jiO0GIxiTGyUwlNEF4QyxLTTGkC46ygiCIlkFZQRBEy6CsIBojogiCqAFdtojGsGO4cLQTkj1orSA/BBosSPagrCAaIxKxb80gSHZgIwjRHPaFD9QVJFvQWkE0h5UUdK4g2YKygmgMTRN8QZVP2PkXDMo6RFlBEH2HnfzBoHQcZQVBEC2DsoJoDDsZE7pskezBniBEc2h2ckaiS96+fd2gURV//8dEv2nXodGuv7cSJCMoK4jG8NDMz5fPvk/vQc7OaVOidejUJDgkiOgHypnp2qV3+XKVCJIRbAQh+oiDg2P/fkO55dDQkG/fooh+kCkzPbr3I0gWxLNnzyYIogmPr34Ti6jS1XI75WTHzk2TkpIqVqgMy9HR31q0qv3hw9v69RpzWzt3aS6TyV6+fD5j5nhX18L9B3aJiY3O7+QMe/lUqgp2weAhPSHa4cP7Xr950bBBs8jIiBUrF2zYtOqf3dvevH1VxLOonV3OOblz9ybs9ceaJafPHH/56lmZ0uUsLS0hXE1qHz++nzn796XL5p4//9+XL+Hly/v4BzzOlBloBEml0goVfLj4c+ZOXrt+2f4D/9y5e6NgQZdCBV0g/MjRA9Omj61Zo86YcYMhA9dvXJJIJMWKlSS55mtQctDrhGrNHIiBgI0gRHM0HGRbpUqNp88CuOVHj+8XKFAwINCXWw0K/hwR8RUimJmZJSTEHz9+cMrkuR3adVHsW6lilUULVsPC7n+OzZ+7AgRo7Pghvn4Px46Zum3rfvt8DsNH9IVE1Gfg5avnU6aOrlSp6o5tB38bNfHNm5dLls6GcDWpgVUyclT/ct4VVyzf2LVrn4uXzqxZuzRTZpQPERUVCfGh1bb5zz3r126HpObNn5qQkACbTE1N4+JiYfffx8+4dOF+vbqNQarCwkKJ8YKygmgMxX5GQ4P4YHQEBvpy33jw83tYv14TqGZc7Q0IeAxulOLFSlIUBRZNt259Gzdq7ubmnl1SAQG+YBRMnTKverVa0FAaNnSMrV2+Q4f2qM9AYICvubl5r54DQNFgxxXLNnaXN17UpHbw0B6JuTk0xCDzbdt0GjhguPovlv17cLeZRDJh/HSXQq6Q/98nzExMTDh2/F9uK1g0ffsMLlOmHJxms6at4VK8fv2C5BqDG3uIsoJoDOiDRqOzKvtUh+f2u3dvYBnsFDABSpUqC1WdyCt2ZZ9qipilSpZVnxTsDtUbqjq3CrUU2lZ+/o/U7+VdriJo1pRpY6Dyfw76BM0csDvUp/b27avixUuJxWnTgDdv1mb0b5PUHOLtu9cQ38QkzVlpZWVV2M3j5ctn30+tVNqp2djYwi8IK8k9hjYTBbpsEZ2TP79z4cIegU/8HB2dQFygMfLseSBU6WbNWoO3olvXPoqY0BRSnxTURnjyQ9+zciDYO+r3KlG81OJFa65du7h5y9oNG1eBkPXrO8Tbu4Ka1OLj43JMVpnIiK/gGFIOMbewSEhMUKz+zEvflMjADACUFYQPoCaDewUqqpdXMfCVlitXaeOmVeC+/fz5I/gyc58OCJOFhcWC+auUA8WinD8tAs0c+INGzcOHdw8d3jt12pjDh86rSc3Kyjo+IZ7kGksrq6TkJOWQxIQEN1d3ohXQWkGMHoot45o9PX18qm3cuMrayqaCvD8I2kHg1Lhw4bS7uyc4NXKfTtGiJRITE8Ez6urixoVAV1E+uxzMCl/fh8kpySArTk75wUSCPhrolAkNC1GTWsmSZU6cPJSamsq1ay5eOnv69LEli9dmd4iSJcqcPXcSbB/OBRMTG/Ph47umTVsRQYK+FURzKBGl4dOzUsWqUI1v377mXbYCrILBAm7aw0f2Va5cPcd9C7t7wu+VK+efPgsEq6datVrLl8+DnhQwdo4e+3fosN5nzhxXnwK0v2bPmXji5OFv36IgETgu6EvBAoXUpNaqZfuUlJSVqxY+eHj3+o3LW7audXTKD64W5cwoH6JNm07QboK+akjq/fu3ixbPNJeYt2zRnggStFYQjWHYTh3NPAXW1tbw/H/+/InCP1q2bPkjRw8oVtUApgR4TLfv2ASStGrln9DFe/zEobnzpzx9GgAum8aNW3Ts2E19Cl1+6QWCsm79cpAJcN80bNBs1crNnBmSXWrQmwPuGFCc02eOSyQS6L4ZNGhk1swoDuHmWnjWzMV//721W4/W4BIuXdr7j9VbwXFLBAl+2h3RmL9mvTeVUB1GeBCEF57fjb575svIlcWIgYDWCoIgWgZlBdEYsZgS6dm3gvbs3bF37w6Vmzw8vdat2UYQHkFZQTSG0b+WM3hMGzRoqnKTidjgCznNGNgsnygriMawc9nq2YfGbaxt4I8YKSIN35bIc1BWEATRMigriMbg58cQ9eBwOERjaBqHJSDqQGsF0Rg97AlC9AqUFURjZDJGpGcuW0SvQFlBNAZ9K4h60LeCaAz6VhD1oLWCIIiWQVlBEETLoKwgGmNhQYlNzQjCFzQRm5kZkr8CfSuIxtgXsEiITSEIX4S+i5dYoqwgRk2L/s7J8bK4SHTb8kTYh4Qy1XP7sTd9AGUF+RHqdnQ+tvFdSiJBdM2B5R9ciphXbWZIsoKzwyE/yOcXiSf/CrGwMbG2M0uVpn7fQH2fJp5iyxdFiTK/8cyGsF8b+j76haLS3v1XRP4eIl/gwrMkxX5gUTkwPTKbCRUHpbOsynOrOJZysoo4FDdzr1KEtPhUxkCRfPZwGcl41PTEFNdERDE0/f27kFkicJiamyTGpMZ+S/Yqa9O0jzMxKFBWkJ/ixObQqPCUpHjVskJEDKFVyYpYXi2VK3lWWcm0oCophmL/yyAr6WLBJphFVmSp7JAb7qNi8urNpCeuLjOU3KbPKkmcaCoHwh+dmvGgacr6vaLBcWmGptJ3VBZNZSQWYks7sxrN8xUuaUEMDZQVRECcOHHi0aNHs2bNIoguwQ5mREAovvuD6BS8xIiAUHweDNEpKCuIgEBrhR/wEiMCAmWFH/ASIwICZYUf8BIjAgJlhR9wlC0iIFBW+AEvMSIgUFb4AS8xIiBQVvgBLzEiIFBW+AEvMSIgcDgcP6CsIAICrRV+wEuMCAiUFX7AS4wICJQVfsBLjAgIlBV+wEuMCAh02fIDygoiINBa4Qe8xIiAQFnhB7zEiIBAWeEHvMSIgABZQd8KD6CsIAICrRV+wEuMCAiUFX7AS4wICJQVfsBLjAgIGxsb7ttjiE5BWUEERHx8fEpKCkF0DMoKIiCgG0gqlRJEx6CsIAICHCvgXiGIjkFZQQQEygo/oKwgAgJlhR9QVhABAbIik8kIomNQVhABgdYKP6CsIAICZYUfUFYQAYHc338IAAAH/0lEQVSywg8oK4iAQFnhB5QVRECgrPADygoiIFBW+AFlBREQKCv8gLKCCAiUFX5AWUEEBMoKP6CsIAICZYUfUFYQAYGywg8UwzAEQYyaNm3aBAUFQVGnKEokEsECTdMeHh5Hjx4liA4QEQQxdjp16mRqaioWi0FTYBXExczMDAIJohtQVhDjp2fPnoULF1YOAVOlQ4cOBNENKCuI8QOmSteuXSUSCbcKZkvTpk2tra0JohtQVhBB8MsvvygMFnd3dzRVdArKCiIU+vTpY2VlBY6VOnXqODo6EkRnYE8Qoo9EBElf+8ZFhKdIk2lpcob53CgRYWgiogidpeRSFCHywAxbKCISUbSMDXv18pVMlupV1MvMTCIWE+WJ4mBfqAqU0r5wIEKzq9wmRfqKCKZmYhMzytbB1L2UpUdpC4Kkg7KC6BF+12L8b36Lj0qV0QxoASViK7JMlkkl5BVbUdeJio2ZQykV5RwSZ+hcFX5Foox8WYFYTME6JMLmkGHMrUw9y1g26pafCB6UFUQvuH0i0v9WtCyVtrCW2LvZ5nOxIgZF0jdp2Lvo+Kg4sKQKeVl0HOFCBAzKCpL3bJ/9ISmBtnezKVjcnhg4saFJQc/DaRndrJdL0YoCbRmhrCB5yaeXSSc2B1k7WbpXcCZGxJcPsV/fRHqUtmo5oAARHigrSJ6REke2zH5TtHphc2vj/Nz6i2sffRo6VG1iRwQGygqSN7x8EH9hX2iZRp7EqHl65ZOzi2nn0a5ESOC4FSQPSEkh5/eGGL2mAGXqF44ISbm47wsREigrSB6wfeZbJw+D987mkpL13J/fj4mPIcIBZQXhmyPrgimRqEDxfEQw2BWw3rP0HREMKCsI3wS/TfSsJKxhHW7lnKQpzJ3TkUQYoKwgvHJkfbCpudjMSLt+1GCT38r/+jciDFBWEF4JfZ/kWFh/O1wPnVi6bG13ogMKeztJk+mQd8lEAKCsIPzxLiCRZhhHT1siSEzNTe+eEUQ7CGUF4Y+AW99MzATX/FEgsZZEhArCWsGZ9xH++PY1BZ7YRGfcf3Ty9v0jIWGvCxUoVrFc4zo1u1HsK9Dk7/1TCaF8KjTff3hucnKCR+FyrZqN9CjsDZtgdffBma/fPoBdalbtSHSJnbNF8PN4IgDQWkH4IzmBkVjqSlYe+Z3df2Sem0vJqeOOtGgy7NqtfcdOreI2iUQmHz4FPPQ9PXrojoUzr5qYmu07PJfbdODogq8Rn4b0W9e3+5LQ8LfPX94kOiNfAetcTsVg6KCsIPxB04zuGkH3Hh7z8qjUsc1EG2uH4l5VmjUafPPuv7Fxab4MsEq6dpju6OAqFpv4lG/25esHCImO+eIXeKFB7d5gudjaOLZuNtLUxJzoDjFhGCYumhg9KCsIf4Cs0Lp5B42m6Xcf/UsUr64IAWVhGPrde19u1Tm/p0RiyS2bm9vAb0JiTGRUECwUcC6i2Kuwa2miSyhCMSkyYuygbwXhD5GIIjKdyEpqaopMJj1zYRP8KYfHxqdZKxSl4gkan8BaDhIzS0WImZluZ0iBk7exN36nNcoKwh8UxSTFpxAdYGZmDupQuWLL8mUbKodDq0fNXlaW7AiaFGmSIiQpWYcu1YSoZJGYEkKdQ1lB+MPe2Szqi64+gexSqERiUmwxr8rcamqqNCIqKJ+dulmU7POx7xC8/+jPtX1gl1dv7llZ6eodyKiQOCIM0LeC8IdbCcuUJCnRDS2bDAt8dvXuw+Osn+WD7z8Hpv25fQQ0jtTsks/O2dO9wtlLm8O/fJBKk3f/O0M+ub6uiItIsLIRxLAdlBWEP2q2dADvQnKcTpSliEfFscN2gY929pLmf+4YlZgU17/nMlNTifq9unea5e5WdvXGPtPmN7C0sK3m05bobGIzaXJq6WqCmCkOZ4dDeGXb7A8MIy5aoxARGN+C4oOfhw9fXowIALRWEF6p2845MS6JCI+wNxEFPIQyET+6bBFeKVbJQnJI/OFhmEdl1c7UR/5nD59YqnITNFISElVPsla9crs2zX8jWgJcM3/9M17lJpqWyb+KpsIF07BOn4Z1+6rcC/qApMmyTqOEMqMtNoIQvmEn3J/1pmxjT5VboTtGKk3KbpOJieqx/2KxKfQxE+2RmBhLNMTExCw7V87Ti+9L+Ng27iGUDx6itYLwjZk1KVbR+tnlD6UbeGTdCsKRnXbwiYWFDdES7x6ESaxMhKMpBH0rSJ7QrHcBW0fT17eCibET9uJbUlzSwDkeREhgIwjJM07vCP/wLKFU/cLESPkc8DXxW8KvC4sQgYHWCpJntOjnbGUnen7tEzFG3twJjo+KF6CmELRWkDzn7N9hr31jbRwt3SsZyeeKw9/EfP0QZetg0muKOxEkKCtI3pOSQP5Z8j4pXmaRz9y1TH4zC0Md4f7J/0vMl3jofa7R0smngeA+vawAZQXRF149ir954mt8TColpkzNTCRWpqbmpiJTUXZFlGKH2VNKq4RREUcRqGK7iCLcbG3ybQxFRIw8DheV/aXkwYrURBQ3vRsXQSSmaCkjTUpNiktOTUmVSWmJubi4j3X9zgLq9FEJygqid9w+EfX5dXzsN1lKsoyWMbTyFC3K4pCdkHCCkykOlTGQsJpBKCZ9KxeSOSkqYwVRyAqHyJSIRSKxmDK3FhfysKjTxsnMWodvKhoQKCsIgmgZHA6HIIiWQVlBEETLoKwgCKJlUFYQBNEyKCsIgmgZlBUEQbTM/wEAAP//A7V+BgAAAAZJREFUAwAy7v6q8wAgKwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_core.messages import get_buffer_string\n",
        "\n",
        "# Search query writing\n",
        "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
        "\n",
        "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
        "\n",
        "First, analyze the full conversation.\n",
        "\n",
        "Pay particular attention to the final question posed by the analyst.\n",
        "\n",
        "Convert this final question into a well-structured web search query\"\"\")\n",
        "\n",
        "def search_web(state: InterviewState):\n",
        "\n",
        "    \"\"\" Retrieve docs from web search \"\"\"\n",
        "\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    # Search\n",
        "    #search_docs = tavily_search.invoke(search_query.search_query) # updated 1.0\n",
        "    data = tavily_search.invoke({\"query\": search_query.search_query})\n",
        "    search_docs = data.get(\"results\", data)\n",
        "\n",
        "\n",
        "     # Format\n",
        "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "        [\n",
        "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
        "            for doc in search_docs\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "def search_wikipedia(state: InterviewState):\n",
        "\n",
        "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
        "\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    # Search\n",
        "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
        "                                  load_max_docs=2).load()\n",
        "\n",
        "     # Format\n",
        "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "        [\n",
        "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
        "            for doc in search_docs\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
        "\n",
        "Here is analyst area of focus: {goals}.\n",
        "\n",
        "You goal is to answer a question posed by the interviewer.\n",
        "\n",
        "To answer question, use this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "When answering questions, follow these guidelines:\n",
        "\n",
        "1. Use only the information provided in the context.\n",
        "\n",
        "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
        "\n",
        "3. The context contain sources at the topic of each individual document.\n",
        "\n",
        "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
        "\n",
        "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
        "\n",
        "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
        "\n",
        "[1] assistant/docs/llama3_1.pdf, page 7\n",
        "\n",
        "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
        "\n",
        "def generate_answer(state: InterviewState):\n",
        "\n",
        "    \"\"\" Node to answer a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    # Answer question\n",
        "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
        "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
        "\n",
        "    # Name the message as coming from the expert\n",
        "    answer.name = \"expert\"\n",
        "\n",
        "    # Append it to state\n",
        "    return {\"messages\": [answer]}\n",
        "\n",
        "def save_interview(state: InterviewState):\n",
        "\n",
        "    \"\"\" Save interviews \"\"\"\n",
        "\n",
        "    # Get messages\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Convert interview to a string\n",
        "    interview = get_buffer_string(messages)\n",
        "\n",
        "    # Save to interviews key\n",
        "    return {\"interview\": interview}\n",
        "\n",
        "def route_messages(state: InterviewState,\n",
        "                   name: str = \"expert\"):\n",
        "\n",
        "    \"\"\" Route between question and answer \"\"\"\n",
        "\n",
        "    # Get messages\n",
        "    messages = state[\"messages\"]\n",
        "    max_num_turns = state.get('max_num_turns',2)\n",
        "\n",
        "    # Check the number of expert answers\n",
        "    num_responses = len(\n",
        "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
        "    )\n",
        "\n",
        "    # End if expert has answered more than the max turns\n",
        "    if num_responses >= max_num_turns:\n",
        "        return 'save_interview'\n",
        "\n",
        "    # This router is run after each question - answer pair\n",
        "    # Get the last question asked to check if it signals the end of discussion\n",
        "    last_question = messages[-2]\n",
        "\n",
        "    if \"Thank you so much for your help\" in last_question.content:\n",
        "        return 'save_interview'\n",
        "    return \"ask_question\"\n",
        "\n",
        "section_writer_instructions = \"\"\"You are an expert technical writer.\n",
        "\n",
        "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
        "\n",
        "1. Analyze the content of the source documents:\n",
        "- The name of each source document is at the start of the document, with the <Document tag.\n",
        "\n",
        "2. Create a report structure using markdown formatting:\n",
        "- Use ## for the section title\n",
        "- Use ### for sub-section headers\n",
        "\n",
        "3. Write the report following this structure:\n",
        "a. Title (## header)\n",
        "b. Summary (### header)\n",
        "c. Sources (### header)\n",
        "\n",
        "4. Make your title engaging based upon the focus area of the analyst:\n",
        "{focus}\n",
        "\n",
        "5. For the summary section:\n",
        "- Set up summary with general background / context related to the focus area of the analyst\n",
        "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
        "- Create a numbered list of source documents, as you use them\n",
        "- Do not mention the names of interviewers or experts\n",
        "- Aim for approximately 400 words maximum\n",
        "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
        "\n",
        "6. In the Sources section:\n",
        "- Include all sources used in your report\n",
        "- Provide full links to relevant websites or specific document paths\n",
        "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
        "- It will look like:\n",
        "\n",
        "### Sources\n",
        "[1] Link or Document name\n",
        "[2] Link or Document name\n",
        "\n",
        "7. Be sure to combine sources. For example this is not correct:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "\n",
        "There should be no redundant sources. It should simply be:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "\n",
        "8. Final review:\n",
        "- Ensure the report follows the required structure\n",
        "- Include no preamble before the title of the report\n",
        "- Check that all guidelines have been followed\"\"\"\n",
        "\n",
        "def write_section(state: InterviewState):\n",
        "\n",
        "    \"\"\" Node to answer a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    interview = state[\"interview\"]\n",
        "    context = state[\"context\"]\n",
        "    analyst = state[\"analyst\"]\n",
        "\n",
        "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
        "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
        "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
        "\n",
        "    # Append it to state\n",
        "    return {\"sections\": [section.content]}\n",
        "\n",
        "# Add nodes and edges\n",
        "interview_builder = StateGraph(InterviewState)\n",
        "interview_builder.add_node(\"ask_question\", generate_question)\n",
        "interview_builder.add_node(\"search_web\", search_web)\n",
        "interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
        "interview_builder.add_node(\"answer_question\", generate_answer)\n",
        "interview_builder.add_node(\"save_interview\", save_interview)\n",
        "interview_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "# Flow\n",
        "interview_builder.add_edge(START, \"ask_question\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
        "interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
        "interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
        "interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
        "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
        "interview_builder.add_edge(\"write_section\", END)\n",
        "\n",
        "# Interview\n",
        "memory = MemorySaver()\n",
        "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
        "\n",
        "# View\n",
        "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
        "outputId": "259814ff-495b-4470-f1f9-ab371cc5859e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Analyst(name='Dr. Mira Chen', role='AI Policy Analyst', affiliation='Tech Policy Lab', specialization='Ethical AI frameworks')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Pick one analyst\n",
        "analysts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3750ac4f-f458-4b2d-8bad-32ce34895758",
      "metadata": {
        "id": "3750ac4f-f458-4b2d-8bad-32ce34895758"
      },
      "source": [
        "Here, we run the interview passing an index of the llama3.1 paper, which is related to our topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28",
        "outputId": "b76f1f9a-7a0e-4f12-8064-acf9028da34c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Insights on Ethical AI Researcher\n\n### Summary\nThis section summarizes Dr. Mira Chen's interview insights on Explores the societal, legal, and ethical implications of AI deployment..\n\n### Sources\n[1] Internal research notes."
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# ✅ 1. Imports\n",
        "from typing import Annotated\n",
        "import operator\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.graph import MessagesState, START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Markdown, Image, display\n",
        "\n",
        "# ✅ 2. Define full Analyst model (with all required fields)\n",
        "class Analyst(BaseModel):\n",
        "    name: str\n",
        "    role: str\n",
        "    affiliation: str\n",
        "    persona: str\n",
        "    description: str\n",
        "\n",
        "# ✅ 3. Define InterviewState to match the updated Analyst model\n",
        "class InterviewState(MessagesState):\n",
        "    max_num_turns: int\n",
        "    context: Annotated[list, operator.add]\n",
        "    analyst: Analyst\n",
        "    interview: str\n",
        "    sections: list\n",
        "\n",
        "# ✅ 4. Dummy interview node functions (offline-safe mock logic)\n",
        "def generate_question(state: InterviewState):\n",
        "    analyst = state[\"analyst\"]\n",
        "    question_text = f\"{analyst.name}: Could you tell me more about {analyst.persona.lower()} in {analyst.role.lower()}?\"\n",
        "    return {\"messages\": [HumanMessage(content=question_text)]}\n",
        "\n",
        "def save_interview(state: InterviewState):\n",
        "    interview_text = \"\\n\".join([m.content for m in state[\"messages\"]])\n",
        "    return {\"interview\": interview_text}\n",
        "\n",
        "def write_section(state: InterviewState):\n",
        "    analyst = state[\"analyst\"]\n",
        "    section = f\"## Insights on {analyst.persona}\\n\\n### Summary\\nThis section summarizes {analyst.name}'s interview insights on {analyst.description}.\\n\\n### Sources\\n[1] Internal research notes.\"\n",
        "    return {\"sections\": [section]}\n",
        "\n",
        "# ✅ 5. Build graph\n",
        "builder = StateGraph(InterviewState)\n",
        "builder.add_node(\"ask_question\", generate_question)\n",
        "builder.add_node(\"save_interview\", save_interview)\n",
        "builder.add_node(\"write_section\", write_section)\n",
        "builder.add_edge(START, \"ask_question\")\n",
        "builder.add_edge(\"ask_question\", \"save_interview\")\n",
        "builder.add_edge(\"save_interview\", \"write_section\")\n",
        "builder.add_edge(\"write_section\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "interview_graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# ✅ 6. Create Analyst object\n",
        "analyst = Analyst(\n",
        "    name=\"Dr. Mira Chen\",\n",
        "    role=\"AI Policy Analyst\",\n",
        "    affiliation=\"Tech Policy Lab\",\n",
        "    persona=\"Ethical AI Researcher\",\n",
        "    description=\"Explores the societal, legal, and ethical implications of AI deployment.\"\n",
        ")\n",
        "\n",
        "# ✅ 7. Prepare topic and messages\n",
        "topic = \"Ethical AI frameworks\"\n",
        "messages = [HumanMessage(f\"So you said you were writing an article on {topic}?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# ✅ 8. Run the graph\n",
        "interview = interview_graph.invoke(\n",
        "    {\"analyst\": analyst, \"messages\": messages, \"max_num_turns\": 2},\n",
        "    thread\n",
        ")\n",
        "\n",
        "# ✅ 9. Display output\n",
        "Markdown(interview[\"sections\"][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b739e87-68bb-4e96-a86a-704e84240a6c",
      "metadata": {
        "id": "3b739e87-68bb-4e96-a86a-704e84240a6c"
      },
      "source": [
        "### Parallelze interviews: Map-Reduce\n",
        "\n",
        "We parallelize the interviews via the `Send()` API, a map step.\n",
        "\n",
        "We combine them into the report body in a reduce step.\n",
        "\n",
        "### Finalize\n",
        "\n",
        "We add a final step to write an intro and conclusion to the final report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140",
      "metadata": {
        "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# ✅ Ensure Analyst is already defined before this (from previous cells)\n",
        "# from pydantic import BaseModel\n",
        "# class Analyst(BaseModel):\n",
        "#     name: str\n",
        "#     role: str\n",
        "#     affiliation: str\n",
        "#     persona: str\n",
        "#     description: str\n",
        "\n",
        "class ResearchGraphState(TypedDict):\n",
        "    topic: str  # Research topic\n",
        "    max_analysts: int  # Number of analysts to generate\n",
        "    human_analyst_feedback: str  # Feedback from human editor\n",
        "    analysts: List[Analyst]  # List of AI analyst personas\n",
        "    sections: Annotated[list, operator.add]  # Aggregated sections for Send() API\n",
        "    introduction: str  # Introductory paragraph of the final report\n",
        "    content: str  # Main content (compiled from interviews)\n",
        "    conclusion: str  # Concluding section\n",
        "    final_report: str  # Fully compiled research report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langgraph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mwA2loFJKD6",
        "outputId": "09b693b3-9e21-4196-a49e-c587153c2216"
      },
      "id": "5mwA2loFJKD6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.0.2-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.3/469.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.2 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2224592-d2ff-469d-97bd-928809f896d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c2224592-d2ff-469d-97bd-928809f896d7",
        "outputId": "86d8085d-bf71-436e-b50e-20d948c3e7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Collecting pydantic-core==2.41.4 (from pydantic)\n",
            "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.10\n",
            "    Uninstalling pydantic-2.11.10:\n",
            "      Successfully uninstalled pydantic-2.11.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-2.12.3 pydantic-core-2.41.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydantic"
                ]
              },
              "id": "afabf016a9b84dc18892475811feb0d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Report on Ethical Artificial Intelligence\n\nThis report explores how ethical principles guide the development of AI systems.\n\n**Dr. Mira Chen asks:** What are the biggest ethical concerns in artificial intelligence?\n\n**Answer:** Ethical AI ensures transparency, inclusivity, and responsible decision-making.\n\nIn conclusion, ethical AI fosters trust, accountability, and fairness across technology."
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# ✅ STEP 1: Install required packages\n",
        "!pip install -U langchain langchain-core langchain-openai langgraph pillow pydantic\n",
        "\n",
        "# ✅ STEP 2: Import libraries\n",
        "import operator\n",
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel   # ⬅️ use plain Pydantic now\n",
        "\n",
        "# LangChain (latest)\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# LangGraph (latest)\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import Send\n",
        "\n",
        "# Optional (for report display)\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# ✅ STEP 3: Analyst model\n",
        "class Analyst(BaseModel):\n",
        "    name: str\n",
        "    persona: str\n",
        "    description: str\n",
        "    expertise: str\n",
        "\n",
        "# ✅ STEP 4: Define the shared graph state\n",
        "class ResearchGraphState(TypedDict):\n",
        "    topic: str\n",
        "    max_analysts: int\n",
        "    human_analyst_feedback: str\n",
        "    analysts: List[Analyst]\n",
        "    sections: Annotated[list, operator.add]\n",
        "    introduction: str\n",
        "    content: str\n",
        "    conclusion: str\n",
        "    final_report: str\n",
        "\n",
        "# ✅ STEP 5: Mock LLM (so you can run without API key)\n",
        "def fake_llm_response(prompt: str) -> str:\n",
        "    \"\"\"Simple fake LLM generator.\"\"\"\n",
        "    if \"introduction\" in prompt.lower():\n",
        "        return \"This report explores how ethical principles guide the development of AI systems.\"\n",
        "    elif \"conclusion\" in prompt.lower():\n",
        "        return \"In conclusion, ethical AI fosters trust, accountability, and fairness across technology.\"\n",
        "    elif \"question\" in prompt.lower():\n",
        "        return \"What are the biggest ethical concerns in artificial intelligence?\"\n",
        "    else:\n",
        "        return \"Ethical AI ensures transparency, inclusivity, and responsible decision-making.\"\n",
        "\n",
        "# ✅ STEP 6: Define nodes\n",
        "\n",
        "def generate_question(state):\n",
        "    analyst = state[\"analysts\"][0]\n",
        "    question = fake_llm_response(f\"Generate question for {analyst.persona}\")\n",
        "    return {\"sections\": [f\"**{analyst.name} asks:** {question}\"]}\n",
        "\n",
        "def generate_answer(state):\n",
        "    question_text = state[\"sections\"][-1]\n",
        "    answer = fake_llm_response(f\"Answer this: {question_text}\")\n",
        "    return {\"sections\": [f\"**Answer:** {answer}\"]}\n",
        "\n",
        "def generate_report(state):\n",
        "    topic = state[\"topic\"]\n",
        "    intro = fake_llm_response(\"Write an introduction about \" + topic)\n",
        "    conclusion = fake_llm_response(\"Write a conclusion about \" + topic)\n",
        "    content = \"\\n\\n\".join(state[\"sections\"])\n",
        "    final_report = f\"# Report on {topic}\\n\\n{intro}\\n\\n{content}\\n\\n{conclusion}\"\n",
        "    return {\n",
        "        \"introduction\": intro,\n",
        "        \"content\": content,\n",
        "        \"conclusion\": conclusion,\n",
        "        \"final_report\": final_report\n",
        "    }\n",
        "\n",
        "# ✅ STEP 7: Build the LangGraph workflow\n",
        "builder = StateGraph(ResearchGraphState)\n",
        "builder.add_node(\"generate_question\", generate_question)\n",
        "builder.add_node(\"generate_answer\", generate_answer)\n",
        "builder.add_node(\"generate_report\", generate_report)\n",
        "\n",
        "# Define flow\n",
        "builder.add_edge(START, \"generate_question\")\n",
        "builder.add_edge(\"generate_question\", \"generate_answer\")\n",
        "builder.add_edge(\"generate_answer\", \"generate_report\")\n",
        "builder.add_edge(\"generate_report\", END)\n",
        "\n",
        "# ✅ STEP 8: Compile the graph\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "# ✅ STEP 9: Setup analyst and topic\n",
        "analyst = Analyst(\n",
        "    name=\"Dr. Mira Chen\",\n",
        "    persona=\"AI Ethics Researcher\",\n",
        "    description=\"Focuses on fairness and transparency in AI.\",\n",
        "    expertise=\"Ethical AI frameworks\"\n",
        ")\n",
        "\n",
        "topic = \"Ethical Artificial Intelligence\"\n",
        "\n",
        "# ✅ STEP 10: Run the graph\n",
        "result = graph.invoke(\n",
        "    {\n",
        "        \"analysts\": [analyst],\n",
        "        \"topic\": topic,\n",
        "        \"max_analysts\": 1,\n",
        "        \"human_analyst_feedback\": \"\",\n",
        "        \"sections\": [],\n",
        "        \"introduction\": \"\",\n",
        "        \"content\": \"\",\n",
        "        \"conclusion\": \"\",\n",
        "        \"final_report\": \"\"\n",
        "    },\n",
        "    {\"configurable\": {\"thread_id\": \"demo\"}}\n",
        ")\n",
        "\n",
        "# ✅ STEP 11: Display final report\n",
        "Markdown(result[\"final_report\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0",
      "metadata": {
        "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0"
      },
      "source": [
        "Let's ask an open-ended question about LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
      "metadata": {
        "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
        "outputId": "118f92dc-f76c-4ce3-9759-1c78a90f6a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Initiating Research Graph for topic: The benefits of adopting LangGraph as an agent framework\n",
            "\n",
            "✅ Analysts created successfully.\n",
            "🧩 Analysts Created:\n",
            "============================================================\n",
            "\n",
            "🔹 Analyst 1\n",
            "Name: Aarav Mehta\n",
            "Affiliation: Open Research Collective\n",
            "Role: AI Systems Architect\n",
            "Description: Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for The benefits of adopting LangGraph as an agent framework.\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔹 Analyst 2\n",
            "Name: Sophia Ramirez\n",
            "Affiliation: NextGen AI Lab\n",
            "Role: Machine Learning Strategist\n",
            "Description: Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\n",
            "------------------------------------------------------------\n",
            "\n",
            "🔹 Analyst 3\n",
            "Name: Liam Chen\n",
            "Affiliation: Cognitive Automation Institute\n",
            "Role: Research Engineer\n",
            "Description: Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\n",
            "------------------------------------------------------------\n",
            "\n",
            "✅ Graph execution paused at 'human_feedback' node.\n",
            "🔍 Review analyst profiles and provide feedback before proceeding.\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import operator\n",
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import Send\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "# --- Define ResearchGraphState ---\n",
        "class ResearchGraphState(TypedDict):\n",
        "    topic: str\n",
        "    max_analysts: int\n",
        "    human_analyst_feedback: str\n",
        "    analysts: list\n",
        "    sections: Annotated[list, operator.add]\n",
        "    introduction: str\n",
        "    content: str\n",
        "    conclusion: str\n",
        "    final_report: str\n",
        "\n",
        "\n",
        "# --- Analyst class ---\n",
        "class Analyst:\n",
        "    def __init__(self, name, affiliation, role, description):\n",
        "        self.name = name\n",
        "        self.affiliation = affiliation\n",
        "        self.role = role\n",
        "        self.description = description\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"name\": self.name,\n",
        "            \"affiliation\": self.affiliation,\n",
        "            \"role\": self.role,\n",
        "            \"description\": self.description\n",
        "        }\n",
        "\n",
        "\n",
        "# --- Create analysts (tweaked version) ---\n",
        "def create_analysts(state: ResearchGraphState):\n",
        "    topic = state[\"topic\"]\n",
        "    analyst_profiles = [\n",
        "        {\n",
        "            \"name\": \"Aarav Mehta\",\n",
        "            \"affiliation\": \"Open Research Collective\",\n",
        "            \"role\": \"AI Systems Architect\",\n",
        "            \"description\": f\"Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for {topic}.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sophia Ramirez\",\n",
        "            \"affiliation\": \"NextGen AI Lab\",\n",
        "            \"role\": \"Machine Learning Strategist\",\n",
        "            \"description\": f\"Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Liam Chen\",\n",
        "            \"affiliation\": \"Cognitive Automation Institute\",\n",
        "            \"role\": \"Research Engineer\",\n",
        "            \"description\": f\"Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    analysts = [Analyst(**profile).to_dict() for profile in analyst_profiles]\n",
        "\n",
        "    print(\"✅ Analysts created successfully.\")\n",
        "    return {\"analysts\": analysts}\n",
        "\n",
        "\n",
        "# --- Other graph node functions ---\n",
        "def human_feedback(state: ResearchGraphState):\n",
        "    print(\"🧠 Waiting for human analyst feedback...\")\n",
        "    return {\"human_analyst_feedback\": \"Feedback noted and saved.\"}\n",
        "\n",
        "\n",
        "def conduct_interview(state: ResearchGraphState):\n",
        "    print(\"🎤 Conducting expert interviews...\")\n",
        "    return {\"sections\": [\"Interview section on LangGraph’s efficiency and adaptability\"]}\n",
        "\n",
        "\n",
        "def write_report(state: ResearchGraphState):\n",
        "    print(\"📝 Writing report content...\")\n",
        "    return {\"content\": \"LangGraph provides a modular and traceable architecture for building coordinated agent workflows.\"}\n",
        "\n",
        "\n",
        "def write_introduction(state: ResearchGraphState):\n",
        "    print(\"📄 Drafting introduction...\")\n",
        "    return {\"introduction\": f\"This research delves into how LangGraph simplifies agent-based development and coordination in AI systems.\"}\n",
        "\n",
        "\n",
        "def write_conclusion(state: ResearchGraphState):\n",
        "    print(\"🔚 Adding conclusion section...\")\n",
        "    return {\"conclusion\": \"Overall, adopting LangGraph streamlines agent orchestration, improves transparency, and enhances the research-to-deployment pipeline.\"}\n",
        "\n",
        "\n",
        "def finalize_report(state: ResearchGraphState):\n",
        "    print(\"📘 Compiling final report...\")\n",
        "    final_report = f\"\"\"\n",
        "    Title: Research Report on {state['topic']}\n",
        "\n",
        "    Introduction: {state['introduction']}\n",
        "    Content: {state['content']}\n",
        "    Conclusion: {state['conclusion']}\n",
        "    \"\"\"\n",
        "    return {\"final_report\": final_report}\n",
        "\n",
        "\n",
        "# --- Build Graph ---\n",
        "memory = MemorySaver()\n",
        "builder = StateGraph(ResearchGraphState)\n",
        "\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_node(\"conduct_interview\", conduct_interview)\n",
        "builder.add_node(\"write_report\", write_report)\n",
        "builder.add_node(\"write_introduction\", write_introduction)\n",
        "builder.add_node(\"write_conclusion\", write_conclusion)\n",
        "builder.add_node(\"finalize_report\", finalize_report)\n",
        "\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_edge(\"human_feedback\", \"conduct_interview\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
        "builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
        "builder.add_edge(\"finalize_report\", END)\n",
        "\n",
        "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
        "\n",
        "\n",
        "# --- Stream Execution (Tweaked Version) ---\n",
        "max_analysts = 3\n",
        "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
        "thread = {\"configurable\": {\"thread_id\": \"research_thread_01\"}}\n",
        "\n",
        "print(f\"\\n🚀 Initiating Research Graph for topic: {topic}\\n\")\n",
        "\n",
        "for event in graph.stream(\n",
        "    {\"topic\": topic, \"max_analysts\": max_analysts},\n",
        "    thread,\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    analysts = event.get(\"analysts\", [])\n",
        "    if analysts:\n",
        "        print(\"🧩 Analysts Created:\\n\" + \"=\" * 60)\n",
        "        for idx, analyst in enumerate(analysts, 1):\n",
        "            print(f\"\\n🔹 Analyst {idx}\")\n",
        "            print(f\"Name: {analyst['name']}\")\n",
        "            print(f\"Affiliation: {analyst['affiliation']}\")\n",
        "            print(f\"Role: {analyst['role']}\")\n",
        "            print(f\"Description: {analyst['description']}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "print(\"\\n✅ Graph execution paused at 'human_feedback' node.\")\n",
        "print(\"🔍 Review analyst profiles and provide feedback before proceeding.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
      "metadata": {
        "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
        "outputId": "72b63073-f8b1-47c0-8410-f93e753e4b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Human feedback successfully added to the research graph.\n",
            "📌 Feedback noted: Add an industry-level analyst (GenAI startup CEO).\n"
          ]
        }
      ],
      "source": [
        "# 🧠 Simulating human feedback update to the research graph\n",
        "\n",
        "# Update state at the 'human_feedback' node as if you (the human) gave an instruction\n",
        "graph.update_state(\n",
        "    thread,\n",
        "    {\n",
        "        \"human_analyst_feedback\": \"Include an additional expert — the CEO of a GenAI-native startup — to broaden the industry perspective.\"\n",
        "    },\n",
        "    as_node=\"human_feedback\"\n",
        ")\n",
        "\n",
        "print(\"✅ Human feedback successfully added to the research graph.\")\n",
        "print(\"📌 Feedback noted: Add an industry-level analyst (GenAI startup CEO).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
      "metadata": {
        "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
        "outputId": "d4600186-5397-4ecb-bb3f-352effa8de0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Resuming Research Graph after human feedback...\n",
            "\n",
            "✅ Updated Analyst Team:\n",
            "\n",
            "🧩 Name: Aarav Mehta\n",
            "🏢 Affiliation: Open Research Collective\n",
            "🎯 Role: AI Systems Architect\n",
            "🧠 Description: Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for The benefits of adopting LangGraph as an agent framework.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Sophia Ramirez\n",
            "🏢 Affiliation: NextGen AI Lab\n",
            "🎯 Role: Machine Learning Strategist\n",
            "🧠 Description: Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Liam Chen\n",
            "🏢 Affiliation: Cognitive Automation Institute\n",
            "🎯 Role: Research Engineer\n",
            "🧠 Description: Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\n",
            "--------------------------------------------------\n",
            "🎤 Conducting expert interviews...\n",
            "✅ Updated Analyst Team:\n",
            "\n",
            "🧩 Name: Aarav Mehta\n",
            "🏢 Affiliation: Open Research Collective\n",
            "🎯 Role: AI Systems Architect\n",
            "🧠 Description: Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for The benefits of adopting LangGraph as an agent framework.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Sophia Ramirez\n",
            "🏢 Affiliation: NextGen AI Lab\n",
            "🎯 Role: Machine Learning Strategist\n",
            "🧠 Description: Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Liam Chen\n",
            "🏢 Affiliation: Cognitive Automation Institute\n",
            "🎯 Role: Research Engineer\n",
            "🧠 Description: Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\n",
            "--------------------------------------------------\n",
            "📄 Drafting introduction...\n",
            "📝 Writing report content...\n",
            "🔚 Adding conclusion section...\n",
            "✅ Updated Analyst Team:\n",
            "\n",
            "🧩 Name: Aarav Mehta\n",
            "🏢 Affiliation: Open Research Collective\n",
            "🎯 Role: AI Systems Architect\n",
            "🧠 Description: Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for The benefits of adopting LangGraph as an agent framework.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Sophia Ramirez\n",
            "🏢 Affiliation: NextGen AI Lab\n",
            "🎯 Role: Machine Learning Strategist\n",
            "🧠 Description: Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Liam Chen\n",
            "🏢 Affiliation: Cognitive Automation Institute\n",
            "🎯 Role: Research Engineer\n",
            "🧠 Description: Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\n",
            "--------------------------------------------------\n",
            "📘 Compiling final report...\n",
            "✅ Updated Analyst Team:\n",
            "\n",
            "🧩 Name: Aarav Mehta\n",
            "🏢 Affiliation: Open Research Collective\n",
            "🎯 Role: AI Systems Architect\n",
            "🧠 Description: Focuses on integrating agent-based frameworks like LangGraph to optimize multi-agent collaboration for The benefits of adopting LangGraph as an agent framework.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Sophia Ramirez\n",
            "🏢 Affiliation: NextGen AI Lab\n",
            "🎯 Role: Machine Learning Strategist\n",
            "🧠 Description: Explores scalable deployment and orchestration benefits of frameworks such as LangGraph in applied AI environments.\n",
            "--------------------------------------------------\n",
            "🧩 Name: Liam Chen\n",
            "🏢 Affiliation: Cognitive Automation Institute\n",
            "🎯 Role: Research Engineer\n",
            "🧠 Description: Investigates workflow automation and reproducibility improvements offered by LangGraph in agent research workflows.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# 🔁 Resume the research graph after applying human feedback\n",
        "\n",
        "print(\"🔄 Resuming Research Graph after human feedback...\\n\")\n",
        "\n",
        "for event in graph.stream(\n",
        "    None,                  # Continue from where we paused\n",
        "    thread,                # Same thread to preserve context\n",
        "    stream_mode=\"values\"   # Stream values only\n",
        "):\n",
        "    analysts = event.get(\"analysts\", [])\n",
        "    if analysts:\n",
        "        print(\"✅ Updated Analyst Team:\\n\")\n",
        "        for analyst in analysts:\n",
        "            print(f\"🧩 Name: {analyst['name']}\")\n",
        "            print(f\"🏢 Affiliation: {analyst['affiliation']}\")\n",
        "            print(f\"🎯 Role: {analyst['role']}\")\n",
        "            print(f\"🧠 Description: {analyst['description']}\")\n",
        "            print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0af41f54-88d9-4597-98b0-444c08322095",
      "metadata": {
        "id": "0af41f54-88d9-4597-98b0-444c08322095",
        "outputId": "a0766769-aee0-4510-fbbd-bbafcb41d76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Continuing Research Graph with final analyst team...\n",
            "\n",
            "📝 Final Research Report:\n",
            "\n",
            "    Title: Research Report on The benefits of adopting LangGraph as an agent framework\n",
            "    \n",
            "    Introduction: This research delves into how LangGraph simplifies agent-based development and coordination in AI systems.\n",
            "    Content: LangGraph provides a modular and traceable architecture for building coordinated agent workflows.\n",
            "    Conclusion: Overall, adopting LangGraph streamlines agent orchestration, improves transparency, and enhances the research-to-deployment pipeline.\n",
            "    \n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"🚀 Continuing Research Graph with final analyst team...\\n\")\n",
        "\n",
        "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
        "    if event.get(\"final_report\"):\n",
        "        print(\"📝 Final Research Report:\")\n",
        "        print(event[\"final_report\"])\n",
        "        print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
      "metadata": {
        "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
        "outputId": "d1a15241-d914-4621-846e-c1133657aab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Continuing Research Process...\n",
            "\n",
            "\n",
            "✅ Research Graph Execution Complete.\n"
          ]
        }
      ],
      "source": [
        "print(\"🚀 Continuing Research Process...\\n\")\n",
        "\n",
        "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
        "    node_name = next(iter(event.keys()))\n",
        "    print(f\"🔹 Current Node Active: {node_name}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\n✅ Research Graph Execution Complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
      "metadata": {
        "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
        "outputId": "69038c05-cfb1-4646-dbe4-b5de51652165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧾 Final Research Report Generated Successfully!\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    Title: Research Report on The benefits of adopting LangGraph as an agent framework\n    \n    Introduction: This research delves into how LangGraph simplifies agent-based development and coordination in AI systems.\n    Content: LangGraph provides a modular and traceable architecture for building coordinated agent workflows.\n    Conclusion: Overall, adopting LangGraph streamlines agent orchestration, improves transparency, and enhances the research-to-deployment pipeline.\n    "
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# 🧠 Retrieve the final graph state\n",
        "final_state = graph.get_state(thread)\n",
        "report = final_state.values.get(\"final_report\", \"⚠️ No final report found. Check graph execution.\")\n",
        "\n",
        "# 📄 Display formatted research report\n",
        "print(\"\\n🧾 Final Research Report Generated Successfully!\\n\")\n",
        "display(Markdown(report))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3",
      "metadata": {
        "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3"
      },
      "source": [
        "We can look at the trace:\n",
        "\n",
        "https://smith.langchain.com/public/2933a7bb-bcef-4d2d-9b85-cc735b22ca0c/r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808bd094",
      "metadata": {
        "id": "808bd094"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}